[23:18:01.359082] Start training for 800 epochs
[23:18:01.361322] log_dir: /proj/cloudrobotics-nest/users/Stacking/dataset/CloudGripper_push_1k/pre_trained_weights/vit_base_single_node_s_d
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[23:18:54.342478] torch.Size([256, 3, 224, 224])
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[23:20:10.241887] Epoch: [0]  [   0/1527]  eta: 1 day, 3:56:14  lr: 0.000000  loss: 1.6486 (1.6486)  time: 65.8639  data: 33.3647  max mem: 21787
[23:21:38.165665] Epoch: [0]  [  20/1527]  eta: 3:03:55  lr: 0.000000  loss: 1.6460 (1.6399)  time: 4.3960  data: 0.7471  max mem: 22633
[23:23:26.786596] Epoch: [0]  [  40/1527]  eta: 2:38:36  lr: 0.000001  loss: 1.5546 (1.5993)  time: 5.4309  data: 0.7504  max mem: 22633
[23:25:26.084057] Epoch: [0]  [  60/1527]  eta: 2:32:59  lr: 0.000001  loss: 1.4016 (1.5361)  time: 5.9648  data: 0.0003  max mem: 22633
[23:27:24.507692] Epoch: [0]  [  80/1527]  eta: 2:28:54  lr: 0.000002  loss: 1.2298 (1.4615)  time: 5.9211  data: 0.4140  max mem: 22633
[23:29:19.380761] Epoch: [0]  [ 100/1527]  eta: 2:24:49  lr: 0.000002  loss: 1.0888 (1.3891)  time: 5.7436  data: 0.0005  max mem: 22633
[23:31:03.272334] Epoch: [0]  [ 120/1527]  eta: 2:19:19  lr: 0.000002  loss: 0.9907 (1.3239)  time: 5.1945  data: 0.0004  max mem: 22633
[23:32:43.471064] Epoch: [0]  [ 140/1527]  eta: 2:14:17  lr: 0.000003  loss: 0.9241 (1.2671)  time: 5.0098  data: 0.0008  max mem: 22633
[23:34:44.571630] Epoch: [0]  [ 160/1527]  eta: 2:13:02  lr: 0.000003  loss: 0.8684 (1.2178)  time: 6.0549  data: 0.2811  max mem: 22633
[23:36:39.368688] Epoch: [0]  [ 180/1527]  eta: 2:10:51  lr: 0.000004  loss: 0.8281 (1.1749)  time: 5.7398  data: 0.0084  max mem: 22633
[23:38:37.678487] Epoch: [0]  [ 200/1527]  eta: 2:09:05  lr: 0.000004  loss: 0.7967 (1.1374)  time: 5.9154  data: 0.1138  max mem: 22633
[23:40:36.019920] Epoch: [0]  [ 220/1527]  eta: 2:07:18  lr: 0.000004  loss: 0.7776 (1.1047)  time: 5.9158  data: 0.4407  max mem: 22633
[23:42:24.357357] Epoch: [0]  [ 240/1527]  eta: 2:04:35  lr: 0.000005  loss: 0.7594 (1.0762)  time: 5.4168  data: 0.0130  max mem: 22633
[23:44:25.251326] Epoch: [0]  [ 260/1527]  eta: 2:03:02  lr: 0.000005  loss: 0.7488 (1.0512)  time: 6.0446  data: 0.2852  max mem: 22633
[23:46:23.179906] Epoch: [0]  [ 280/1527]  eta: 2:01:12  lr: 0.000006  loss: 0.7415 (1.0292)  time: 5.8964  data: 0.0004  max mem: 22633
[23:48:21.451082] Epoch: [0]  [ 300/1527]  eta: 1:59:22  lr: 0.000006  loss: 0.7356 (1.0097)  time: 5.9135  data: 0.0004  max mem: 22633
[23:50:22.277828] Epoch: [0]  [ 320/1527]  eta: 1:57:40  lr: 0.000006  loss: 0.7299 (0.9923)  time: 6.0413  data: 0.0004  max mem: 22633
[23:52:18.272106] Epoch: [0]  [ 340/1527]  eta: 1:55:40  lr: 0.000007  loss: 0.7280 (0.9768)  time: 5.7996  data: 0.0003  max mem: 22633
[23:54:09.231877] Epoch: [0]  [ 360/1527]  eta: 1:53:24  lr: 0.000007  loss: 0.7252 (0.9629)  time: 5.5479  data: 0.0004  max mem: 22633
[23:56:14.588152] Epoch: [0]  [ 380/1527]  eta: 1:51:53  lr: 0.000007  loss: 0.7238 (0.9503)  time: 6.2677  data: 0.0044  max mem: 22633
[23:58:14.865690] Epoch: [0]  [ 400/1527]  eta: 1:50:05  lr: 0.000008  loss: 0.7240 (0.9390)  time: 6.0138  data: 0.2320  max mem: 22633
[00:00:05.489572] Epoch: [0]  [ 420/1527]  eta: 1:47:51  lr: 0.000008  loss: 0.7224 (0.9287)  time: 5.5311  data: 0.0004  max mem: 22633
[00:02:12.274260] Epoch: [0]  [ 440/1527]  eta: 1:46:18  lr: 0.000009  loss: 0.7216 (0.9193)  time: 6.3392  data: 0.0004  max mem: 22633
[00:04:07.829954] Epoch: [0]  [ 460/1527]  eta: 1:44:17  lr: 0.000009  loss: 0.7212 (0.9108)  time: 5.7777  data: 0.0093  max mem: 22633
[00:06:02.733910] Epoch: [0]  [ 480/1527]  eta: 1:42:14  lr: 0.000009  loss: 0.7222 (0.9029)  time: 5.7451  data: 0.0004  max mem: 22633
[00:07:49.499710] Epoch: [0]  [ 500/1527]  eta: 1:39:56  lr: 0.000010  loss: 0.7218 (0.8957)  time: 5.3382  data: 0.0005  max mem: 22633
[00:09:41.792860] Epoch: [0]  [ 520/1527]  eta: 1:37:50  lr: 0.000010  loss: 0.7195 (0.8889)  time: 5.6143  data: 0.0004  max mem: 22633
[00:11:40.960083] Epoch: [0]  [ 540/1527]  eta: 1:35:58  lr: 0.000011  loss: 0.7180 (0.8826)  time: 5.9583  data: 0.0003  max mem: 22633
[00:13:32.096200] Epoch: [0]  [ 560/1527]  eta: 1:33:52  lr: 0.000011  loss: 0.7163 (0.8767)  time: 5.5567  data: 0.0004  max mem: 22633
[00:15:56.420631] Epoch: [0]  [ 580/1527]  eta: 1:32:41  lr: 0.000011  loss: 0.7166 (0.8712)  time: 7.2158  data: 0.0005  max mem: 22633
[00:17:54.486817] Epoch: [0]  [ 600/1527]  eta: 1:30:44  lr: 0.000012  loss: 0.7163 (0.8661)  time: 5.9032  data: 0.0004  max mem: 22633
[00:19:48.042416] Epoch: [0]  [ 620/1527]  eta: 1:28:41  lr: 0.000012  loss: 0.7163 (0.8612)  time: 5.6777  data: 0.0003  max mem: 22633
[00:21:41.636227] Epoch: [0]  [ 640/1527]  eta: 1:26:39  lr: 0.000013  loss: 0.7144 (0.8566)  time: 5.6796  data: 0.0004  max mem: 22633
[00:23:45.205643] Epoch: [0]  [ 660/1527]  eta: 1:24:50  lr: 0.000013  loss: 0.7131 (0.8523)  time: 6.1784  data: 0.0005  max mem: 22633
[00:25:38.256462] Epoch: [0]  [ 680/1527]  eta: 1:22:47  lr: 0.000013  loss: 0.7122 (0.8482)  time: 5.6525  data: 0.0004  max mem: 22633
[00:27:53.173213] Epoch: [0]  [ 700/1527]  eta: 1:21:10  lr: 0.000014  loss: 0.7091 (0.8443)  time: 6.7457  data: 0.0003  max mem: 22633
[00:29:52.179557] Epoch: [0]  [ 720/1527]  eta: 1:19:14  lr: 0.000014  loss: 0.7107 (0.8405)  time: 5.9502  data: 0.0003  max mem: 22633
[00:31:48.534393] Epoch: [0]  [ 740/1527]  eta: 1:17:14  lr: 0.000015  loss: 0.7096 (0.8370)  time: 5.8177  data: 0.0004  max mem: 22633
[00:33:52.836752] Epoch: [0]  [ 760/1527]  eta: 1:15:23  lr: 0.000015  loss: 0.7076 (0.8336)  time: 6.2150  data: 0.0003  max mem: 22633
[00:35:43.799190] Epoch: [0]  [ 780/1527]  eta: 1:13:19  lr: 0.000015  loss: 0.7079 (0.8304)  time: 5.5481  data: 0.0004  max mem: 22633

[00:37:37.237253] Epoch: [0]  [ 800/1527]  eta: 1:11:17  lr: 0.000016  loss: 0.7077 (0.8274)  time: 5.6718  data: 0.0004  max mem: 22633
[00:39:32.858239] Epoch: [0]  [ 820/1527]  eta: 1:09:17  lr: 0.000016  loss: 0.7062 (0.8244)  time: 5.7810  data: 0.0004  max mem: 22633
[00:41:29.988250] Epoch: [0]  [ 840/1527]  eta: 1:07:19  lr: 0.000017  loss: 0.7042 (0.8216)  time: 5.8564  data: 0.0004  max mem: 22633
[00:43:31.489851] Epoch: [0]  [ 860/1527]  eta: 1:05:25  lr: 0.000017  loss: 0.7040 (0.8188)  time: 6.0750  data: 0.0004  max mem: 22633
[00:45:28.110014] Epoch: [0]  [ 880/1527]  eta: 1:03:26  lr: 0.000017  loss: 0.7032 (0.8162)  time: 5.8309  data: 0.0004  max mem: 22633
[00:47:24.168122] Epoch: [0]  [ 900/1527]  eta: 1:01:28  lr: 0.000018  loss: 0.7024 (0.8137)  time: 5.8028  data: 0.0356  max mem: 22633
[00:49:25.249694] Epoch: [0]  [ 920/1527]  eta: 0:59:32  lr: 0.000018  loss: 0.7029 (0.8113)  time: 6.0540  data: 0.0085  max mem: 22633
[00:51:27.480677] Epoch: [0]  [ 940/1527]  eta: 0:57:37  lr: 0.000018  loss: 0.7016 (0.8090)  time: 6.1115  data: 0.0301  max mem: 22633
[00:53:20.848881] Epoch: [0]  [ 960/1527]  eta: 0:55:37  lr: 0.000019  loss: 0.6997 (0.8067)  time: 5.6683  data: 0.0468  max mem: 22633
[00:55:12.513688] Epoch: [0]  [ 980/1527]  eta: 0:53:36  lr: 0.000019  loss: 0.6990 (0.8045)  time: 5.5832  data: 0.0840  max mem: 22633
[00:57:07.165267] Epoch: [0]  [1000/1527]  eta: 0:51:37  lr: 0.000020  loss: 0.6979 (0.8024)  time: 5.7325  data: 0.0856  max mem: 22633
[00:59:08.850752] Epoch: [0]  [1020/1527]  eta: 0:49:41  lr: 0.000020  loss: 0.6958 (0.8004)  time: 6.0842  data: 0.0625  max mem: 22633
[01:01:07.710254] Epoch: [0]  [1040/1527]  eta: 0:47:44  lr: 0.000020  loss: 0.6959 (0.7984)  time: 5.9429  data: 0.0043  max mem: 22633
[01:03:05.641997] Epoch: [0]  [1060/1527]  eta: 0:45:47  lr: 0.000021  loss: 0.6938 (0.7964)  time: 5.8965  data: 0.0003  max mem: 22633
[01:05:02.448850] Epoch: [0]  [1080/1527]  eta: 0:43:49  lr: 0.000021  loss: 0.6937 (0.7945)  time: 5.8403  data: 0.0004  max mem: 22633
[01:07:02.919680] Epoch: [0]  [1100/1527]  eta: 0:41:52  lr: 0.000022  loss: 0.6954 (0.7927)  time: 6.0235  data: 0.0004  max mem: 22633
[01:08:56.754293] Epoch: [0]  [1120/1527]  eta: 0:39:53  lr: 0.000022  loss: 0.6923 (0.7909)  time: 5.6917  data: 0.0003  max mem: 22633
[01:10:47.088379] Epoch: [0]  [1140/1527]  eta: 0:37:53  lr: 0.000022  loss: 0.6909 (0.7892)  time: 5.5166  data: 0.0004  max mem: 22633
[01:12:47.820779] Epoch: [0]  [1160/1527]  eta: 0:35:56  lr: 0.000023  loss: 0.6917 (0.7875)  time: 6.0366  data: 0.0005  max mem: 22633
[01:14:47.727116] Epoch: [0]  [1180/1527]  eta: 0:34:00  lr: 0.000023  loss: 0.6897 (0.7858)  time: 5.9952  data: 0.0005  max mem: 22633
[01:16:44.396590] Epoch: [0]  [1200/1527]  eta: 0:32:02  lr: 0.000024  loss: 0.6891 (0.7842)  time: 5.8333  data: 0.0004  max mem: 22633
[01:18:50.681900] Epoch: [0]  [1220/1527]  eta: 0:30:06  lr: 0.000024  loss: 0.6877 (0.7826)  time: 6.3142  data: 0.0004  max mem: 22633
[01:20:47.873399] Epoch: [0]  [1240/1527]  eta: 0:28:09  lr: 0.000024  loss: 0.6874 (0.7811)  time: 5.8595  data: 0.0005  max mem: 22633
[01:22:38.736758] Epoch: [0]  [1260/1527]  eta: 0:26:09  lr: 0.000025  loss: 0.6855 (0.7796)  time: 5.5431  data: 0.0004  max mem: 22633
[01:24:25.738240] Epoch: [0]  [1280/1527]  eta: 0:24:10  lr: 0.000025  loss: 0.6850 (0.7781)  time: 5.3500  data: 0.0004  max mem: 22633
[01:26:19.989941] Epoch: [0]  [1300/1527]  eta: 0:22:12  lr: 0.000026  loss: 0.6830 (0.7767)  time: 5.7125  data: 0.0004  max mem: 22633
[01:28:15.536005] Epoch: [0]  [1320/1527]  eta: 0:20:14  lr: 0.000026  loss: 0.6847 (0.7753)  time: 5.7772  data: 0.0042  max mem: 22633
[01:30:21.748570] Epoch: [0]  [1340/1527]  eta: 0:18:18  lr: 0.000026  loss: 0.6815 (0.7739)  time: 6.3106  data: 0.0005  max mem: 22633
[01:32:32.202700] Epoch: [0]  [1360/1527]  eta: 0:16:22  lr: 0.000027  loss: 0.6800 (0.7725)  time: 6.5226  data: 0.0003  max mem: 22633
[01:34:21.635854] Epoch: [0]  [1380/1527]  eta: 0:14:24  lr: 0.000027  loss: 0.6811 (0.7712)  time: 5.4716  data: 0.0004  max mem: 22633
[01:36:20.450118] Epoch: [0]  [1400/1527]  eta: 0:12:26  lr: 0.000028  loss: 0.6804 (0.7699)  time: 5.9406  data: 0.0004  max mem: 22633
[01:38:16.391865] Epoch: [0]  [1420/1527]  eta: 0:10:28  lr: 0.000028  loss: 0.6797 (0.7686)  time: 5.7970  data: 0.0003  max mem: 22633
[01:40:16.217652] Epoch: [0]  [1440/1527]  eta: 0:08:31  lr: 0.000028  loss: 0.6774 (0.7674)  time: 5.9912  data: 0.0005  max mem: 22633
[01:42:14.403957] Epoch: [0]  [1460/1527]  eta: 0:06:33  lr: 0.000029  loss: 0.6760 (0.7662)  time: 5.9092  data: 0.0045  max mem: 22633
[01:44:01.457980] Epoch: [0]  [1480/1527]  eta: 0:04:35  lr: 0.000029  loss: 0.6750 (0.7649)  time: 5.3526  data: 0.0004  max mem: 22633
[01:46:03.172449] Epoch: [0]  [1500/1527]  eta: 0:02:38  lr: 0.000029  loss: 0.6745 (0.7637)  time: 6.0856  data: 0.0003  max mem: 22633
[01:48:17.453214] Epoch: [0]  [1520/1527]  eta: 0:00:41  lr: 0.000030  loss: 0.6739 (0.7625)  time: 6.7140  data: 0.0042  max mem: 22633
[01:49:54.800622] Epoch: [0]  [1526/1527]  eta: 0:00:05  lr: 0.000030  loss: 0.6738 (0.7622)  time: 9.1832  data: 0.0041  max mem: 22633
[01:49:55.138696] Epoch: [0] Total time: 2:30:50 (5.9272 s / it)
[01:49:55.197060] Averaged stats: lr: 0.000030  loss: 0.6738 (0.7622)
[01:49:59.868794] log_dir: /proj/cloudrobotics-nest/users/Stacking/dataset/CloudGripper_push_1k/pre_trained_weights/vit_base_single_node_s_d
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[01:51:04.999757] torch.Size([256, 3, 224, 224])
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[01:52:22.730674] Epoch: [1]  [   0/1527]  eta: 1 day, 0:28:07  lr: 0.000030  loss: 0.6735 (0.6735)  time: 57.6869  data: 22.6535  max mem: 22633
[01:53:48.998444] Epoch: [1]  [  20/1527]  eta: 2:52:10  lr: 0.000030  loss: 0.6720 (0.6723)  time: 4.3133  data: 0.0515  max mem: 22633
[01:55:46.132295] Epoch: [1]  [  40/1527]  eta: 2:37:48  lr: 0.000031  loss: 0.6705 (0.6712)  time: 5.8563  data: 0.0463  max mem: 22633
[01:57:34.741598] Epoch: [1]  [  60/1527]  eta: 2:28:10  lr: 0.000031  loss: 0.6687 (0.6705)  time: 5.4304  data: 0.0652  max mem: 22633
[01:59:32.213024] Epoch: [1]  [  80/1527]  eta: 2:25:02  lr: 0.000032  loss: 0.6666 (0.6700)  time: 5.8735  data: 0.1690  max mem: 22633
[02:01:33.761556] Epoch: [1]  [ 100/1527]  eta: 2:23:20  lr: 0.000032  loss: 0.6667 (0.6694)  time: 6.0774  data: 0.3770  max mem: 22633
[02:03:37.595316] Epoch: [1]  [ 120/1527]  eta: 2:21:57  lr: 0.000032  loss: 0.6681 (0.6692)  time: 6.1916  data: 0.0472  max mem: 22633
[02:05:23.378073] Epoch: [1]  [ 140/1527]  eta: 2:17:26  lr: 0.000033  loss: 0.6654 (0.6688)  time: 5.2891  data: 0.0588  max mem: 22633
[02:07:26.337907] Epoch: [1]  [ 160/1527]  eta: 2:16:01  lr: 0.000033  loss: 0.6625 (0.6680)  time: 6.1479  data: 0.0262  max mem: 22633
[02:09:13.254313] Epoch: [1]  [ 180/1527]  eta: 2:12:29  lr: 0.000034  loss: 0.6629 (0.6675)  time: 5.3455  data: 0.0393  max mem: 22633
[02:11:05.942735] Epoch: [1]  [ 200/1527]  eta: 2:09:56  lr: 0.000034  loss: 0.6626 (0.6671)  time: 5.6340  data: 0.0377  max mem: 22633
[02:13:07.900762] Epoch: [1]  [ 220/1527]  eta: 2:08:24  lr: 0.000034  loss: 0.6594 (0.6664)  time: 6.0978  data: 0.0339  max mem: 22633
[02:15:07.549558] Epoch: [1]  [ 240/1527]  eta: 2:06:36  lr: 0.000035  loss: 0.6600 (0.6659)  time: 5.9824  data: 0.0438  max mem: 22633
[02:17:11.702860] Epoch: [1]  [ 260/1527]  eta: 2:05:07  lr: 0.000035  loss: 0.6598 (0.6654)  time: 6.2076  data: 0.0398  max mem: 22633
[02:19:14.865502] Epoch: [1]  [ 280/1527]  eta: 2:03:30  lr: 0.000036  loss: 0.6579 (0.6649)  time: 6.1580  data: 0.0287  max mem: 22633
[02:21:12.156423] Epoch: [1]  [ 300/1527]  eta: 2:01:24  lr: 0.000036  loss: 0.6545 (0.6642)  time: 5.8645  data: 0.0332  max mem: 22633
[02:23:01.844576] Epoch: [1]  [ 320/1527]  eta: 1:58:52  lr: 0.000036  loss: 0.6556 (0.6637)  time: 5.4843  data: 0.0124  max mem: 22633
[02:24:55.706657] Epoch: [1]  [ 340/1527]  eta: 1:56:38  lr: 0.000037  loss: 0.6542 (0.6631)  time: 5.6930  data: 0.0092  max mem: 22633
[02:26:56.021273] Epoch: [1]  [ 360/1527]  eta: 1:54:48  lr: 0.000037  loss: 0.6526 (0.6625)  time: 6.0156  data: 0.0004  max mem: 22633
[02:28:58.327022] Epoch: [1]  [ 380/1527]  eta: 1:53:03  lr: 0.000037  loss: 0.6522 (0.6620)  time: 6.1148  data: 0.0024  max mem: 22633
[02:30:57.449680] Epoch: [1]  [ 400/1527]  eta: 1:51:07  lr: 0.000038  loss: 0.6491 (0.6613)  time: 5.9561  data: 0.0004  max mem: 22633
[02:32:45.808701] Epoch: [1]  [ 420/1527]  eta: 1:48:42  lr: 0.000038  loss: 0.6477 (0.6608)  time: 5.4179  data: 0.0004  max mem: 22633
[02:34:32.870870] Epoch: [1]  [ 440/1527]  eta: 1:46:18  lr: 0.000039  loss: 0.6485 (0.6602)  time: 5.3530  data: 0.0004  max mem: 22633
[02:36:22.464954] Epoch: [1]  [ 460/1527]  eta: 1:44:03  lr: 0.000039  loss: 0.6447 (0.6596)  time: 5.4796  data: 0.0003  max mem: 22633
[02:38:22.503018] Epoch: [1]  [ 480/1527]  eta: 1:42:12  lr: 0.000039  loss: 0.6444 (0.6590)  time: 6.0018  data: 0.0004  max mem: 22633
[02:40:07.937989] Epoch: [1]  [ 500/1527]  eta: 1:39:51  lr: 0.000040  loss: 0.6422 (0.6584)  time: 5.2717  data: 0.0004  max mem: 22633
[02:41:51.500474] Epoch: [1]  [ 520/1527]  eta: 1:37:29  lr: 0.000040  loss: 0.6437 (0.6578)  time: 5.1780  data: 0.0003  max mem: 22633
[02:43:55.981527] Epoch: [1]  [ 540/1527]  eta: 1:35:48  lr: 0.000041  loss: 0.6425 (0.6572)  time: 6.2237  data: 0.0004  max mem: 22633
[02:45:50.719933] Epoch: [1]  [ 560/1527]  eta: 1:33:48  lr: 0.000041  loss: 0.6391 (0.6566)  time: 5.7368  data: 0.0003  max mem: 22633
[02:47:58.590789] Epoch: [1]  [ 580/1527]  eta: 1:32:11  lr: 0.000041  loss: 0.6384 (0.6561)  time: 6.3931  data: 0.0004  max mem: 22633
[02:49:57.870004] Epoch: [1]  [ 600/1527]  eta: 1:30:18  lr: 0.000042  loss: 0.6371 (0.6555)  time: 5.9638  data: 0.0040  max mem: 22633
[02:51:47.159962] Epoch: [1]  [ 620/1527]  eta: 1:28:10  lr: 0.000042  loss: 0.6350 (0.6549)  time: 5.4644  data: 0.0027  max mem: 22633
[02:53:47.787899] Epoch: [1]  [ 640/1527]  eta: 1:26:18  lr: 0.000043  loss: 0.6378 (0.6544)  time: 6.0313  data: 0.0004  max mem: 22633
[02:55:38.232227] Epoch: [1]  [ 660/1527]  eta: 1:24:13  lr: 0.000043  loss: 0.6342 (0.6538)  time: 5.5219  data: 0.0004  max mem: 22633
[02:57:50.522501] Epoch: [1]  [ 680/1527]  eta: 1:22:36  lr: 0.000043  loss: 0.6349 (0.6532)  time: 6.6144  data: 0.0046  max mem: 22633
[02:59:40.995347] Epoch: [1]  [ 700/1527]  eta: 1:20:32  lr: 0.000044  loss: 0.6352 (0.6527)  time: 5.5236  data: 0.0081  max mem: 22633
[03:01:30.071371] Epoch: [1]  [ 720/1527]  eta: 1:18:26  lr: 0.000044  loss: 0.6321 (0.6522)  time: 5.4537  data: 0.0004  max mem: 22633
[03:03:25.404768] Epoch: [1]  [ 740/1527]  eta: 1:16:28  lr: 0.000045  loss: 0.6284 (0.6516)  time: 5.7666  data: 0.0152  max mem: 22633
[03:05:22.192325] Epoch: [1]  [ 760/1527]  eta: 1:14:32  lr: 0.000045  loss: 0.6268 (0.6510)  time: 5.8393  data: 0.0082  max mem: 22633
[03:07:20.031258] Epoch: [1]  [ 780/1527]  eta: 1:12:36  lr: 0.000045  loss: 0.6289 (0.6504)  time: 5.8919  data: 0.0294  max mem: 22633
[03:09:20.845577] Epoch: [1]  [ 800/1527]  eta: 1:10:43  lr: 0.000046  loss: 0.6275 (0.6498)  time: 6.0406  data: 0.0157  max mem: 22633
[03:11:02.384222] Epoch: [1]  [ 820/1527]  eta: 1:08:33  lr: 0.000046  loss: 0.6230 (0.6492)  time: 5.0765  data: 0.0088  max mem: 22633
[03:13:01.611132] Epoch: [1]  [ 840/1527]  eta: 1:06:39  lr: 0.000047  loss: 0.6231 (0.6486)  time: 5.9613  data: 0.0207  max mem: 22633
[03:14:53.797490] Epoch: [1]  [ 860/1527]  eta: 1:04:40  lr: 0.000047  loss: 0.6204 (0.6480)  time: 5.6091  data: 0.0024  max mem: 22633
[03:16:43.343672] Epoch: [1]  [ 880/1527]  eta: 1:02:38  lr: 0.000047  loss: 0.6233 (0.6475)  time: 5.4772  data: 0.0293  max mem: 22633
[03:18:46.218224] Epoch: [1]  [ 900/1527]  eta: 1:00:47  lr: 0.000048  loss: 0.6212 (0.6469)  time: 6.1437  data: 0.0423  max mem: 22633
[03:20:39.497096] Epoch: [1]  [ 920/1527]  eta: 0:58:48  lr: 0.000048  loss: 0.6178 (0.6463)  time: 5.6638  data: 0.0003  max mem: 22633
[03:22:33.716749] Epoch: [1]  [ 940/1527]  eta: 0:56:51  lr: 0.000048  loss: 0.6196 (0.6457)  time: 5.7109  data: 0.0003  max mem: 22633
[03:24:25.986990] Epoch: [1]  [ 960/1527]  eta: 0:54:52  lr: 0.000049  loss: 0.6161 (0.6451)  time: 5.6134  data: 0.0003  max mem: 22633
[03:26:14.085170] Epoch: [1]  [ 980/1527]  eta: 0:52:52  lr: 0.000049  loss: 0.6133 (0.6445)  time: 5.4048  data: 0.0192  max mem: 22633
[03:28:01.870187] Epoch: [1]  [1000/1527]  eta: 0:50:51  lr: 0.000050  loss: 0.6150 (0.6439)  time: 5.3892  data: 0.0159  max mem: 22633
[03:29:59.523179] Epoch: [1]  [1020/1527]  eta: 0:48:56  lr: 0.000050  loss: 0.6131 (0.6433)  time: 5.8826  data: 0.0081  max mem: 22633
[03:31:46.985384] Epoch: [1]  [1040/1527]  eta: 0:46:57  lr: 0.000050  loss: 0.6097 (0.6426)  time: 5.3730  data: 0.0259  max mem: 22633
[03:33:42.017970] Epoch: [1]  [1060/1527]  eta: 0:45:01  lr: 0.000051  loss: 0.6074 (0.6420)  time: 5.7515  data: 0.0306  max mem: 22633
[03:35:31.653327] Epoch: [1]  [1080/1527]  eta: 0:43:02  lr: 0.000051  loss: 0.6083 (0.6414)  time: 5.4817  data: 0.0440  max mem: 22633
[03:37:10.202533] Epoch: [1]  [1100/1527]  eta: 0:41:00  lr: 0.000052  loss: 0.6080 (0.6408)  time: 4.9274  data: 0.0524  max mem: 22633
[03:39:06.808871] Epoch: [1]  [1120/1527]  eta: 0:39:06  lr: 0.000052  loss: 0.6077 (0.6402)  time: 5.8302  data: 0.0444  max mem: 22633
[03:40:51.913540] Epoch: [1]  [1140/1527]  eta: 0:37:07  lr: 0.000052  loss: 0.6012 (0.6395)  time: 5.2551  data: 0.0609  max mem: 22633
[03:42:44.849800] Epoch: [1]  [1160/1527]  eta: 0:35:11  lr: 0.000053  loss: 0.6015 (0.6389)  time: 5.6467  data: 0.1465  max mem: 22633
[03:44:47.256950] Epoch: [1]  [1180/1527]  eta: 0:33:18  lr: 0.000053  loss: 0.6005 (0.6383)  time: 6.1203  data: 0.7527  max mem: 22633
[03:46:50.134086] Epoch: [1]  [1200/1527]  eta: 0:31:25  lr: 0.000054  loss: 0.5979 (0.6376)  time: 6.1435  data: 0.2014  max mem: 22633
[03:48:42.909539] Epoch: [1]  [1220/1527]  eta: 0:29:29  lr: 0.000054  loss: 0.5996 (0.6370)  time: 5.6387  data: 0.0089  max mem: 22633
[03:50:40.572323] Epoch: [1]  [1240/1527]  eta: 0:27:34  lr: 0.000054  loss: 0.5960 (0.6364)  time: 5.8831  data: 0.0003  max mem: 22633
[03:52:44.062899] Epoch: [1]  [1260/1527]  eta: 0:25:41  lr: 0.000055  loss: 0.5918 (0.6357)  time: 6.1744  data: 0.0004  max mem: 22633
[03:54:44.041361] Epoch: [1]  [1280/1527]  eta: 0:23:46  lr: 0.000055  loss: 0.5905 (0.6351)  time: 5.9989  data: 0.0005  max mem: 22633
[03:56:38.422720] Epoch: [1]  [1300/1527]  eta: 0:21:50  lr: 0.000056  loss: 0.5916 (0.6344)  time: 5.7190  data: 0.0003  max mem: 22633
[03:58:29.566168] Epoch: [1]  [1320/1527]  eta: 0:19:54  lr: 0.000056  loss: 0.5896 (0.6338)  time: 5.5571  data: 0.0003  max mem: 22633
[04:00:28.238688] Epoch: [1]  [1340/1527]  eta: 0:17:59  lr: 0.000056  loss: 0.5862 (0.6331)  time: 5.9336  data: 0.0003  max mem: 22633
[04:02:32.176892] Epoch: [1]  [1360/1527]  eta: 0:16:05  lr: 0.000057  loss: 0.5857 (0.6324)  time: 6.1968  data: 0.0154  max mem: 22633
[04:04:24.370300] Epoch: [1]  [1380/1527]  eta: 0:14:09  lr: 0.000057  loss: 0.5820 (0.6316)  time: 5.6096  data: 0.0039  max mem: 22633
[04:06:21.102262] Epoch: [1]  [1400/1527]  eta: 0:12:13  lr: 0.000058  loss: 0.5829 (0.6310)  time: 5.8365  data: 0.0158  max mem: 22633
[04:08:15.009727] Epoch: [1]  [1420/1527]  eta: 0:10:18  lr: 0.000058  loss: 0.5842 (0.6303)  time: 5.6953  data: 0.0003  max mem: 22633
[04:10:01.794642] Epoch: [1]  [1440/1527]  eta: 0:08:22  lr: 0.000058  loss: 0.5820 (0.6296)  time: 5.3392  data: 0.0003  max mem: 22633
[04:11:58.272548] Epoch: [1]  [1460/1527]  eta: 0:06:26  lr: 0.000059  loss: 0.5774 (0.6290)  time: 5.8238  data: 0.0004  max mem: 22633
[04:13:51.584281] Epoch: [1]  [1480/1527]  eta: 0:04:31  lr: 0.000059  loss: 0.5803 (0.6283)  time: 5.6655  data: 0.0004  max mem: 22633
[04:15:47.072980] Epoch: [1]  [1500/1527]  eta: 0:02:35  lr: 0.000059  loss: 0.5741 (0.6276)  time: 5.7744  data: 0.0004  max mem: 22633
[04:17:42.756332] Epoch: [1]  [1520/1527]  eta: 0:00:40  lr: 0.000060  loss: 0.5712 (0.6269)  time: 5.7841  data: 0.0024  max mem: 22633
[04:19:01.839877] Epoch: [1]  [1526/1527]  eta: 0:00:05  lr: 0.000060  loss: 0.5690 (0.6266)  time: 6.9163  data: 0.0023  max mem: 22633
[04:19:02.103042] Epoch: [1] Total time: 2:27:37 (5.8003 s / it)
[04:19:02.104225] Averaged stats: lr: 0.000060  loss: 0.5690 (0.6267)
[04:19:02.108766] log_dir: /proj/cloudrobotics-nest/users/Stacking/dataset/CloudGripper_push_1k/pre_trained_weights/vit_base_single_node_s_d
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[04:20:07.949630] torch.Size([256, 3, 224, 224])
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[04:21:19.621400] Epoch: [2]  [   0/1527]  eta: 13:23:30  lr: 0.000060  loss: 0.5796 (0.5796)  time: 31.5722  data: 29.9216  max mem: 22633
[04:22:50.533966] Epoch: [2]  [  20/1527]  eta: 2:26:29  lr: 0.000060  loss: 0.5721 (0.5742)  time: 4.5455  data: 0.8683  max mem: 22633
[04:24:45.818603] Epoch: [2]  [  40/1527]  eta: 2:23:43  lr: 0.000061  loss: 0.5716 (0.5732)  time: 5.7641  data: 0.0045  max mem: 22633
[04:26:39.773213] Epoch: [2]  [  60/1527]  eta: 2:20:58  lr: 0.000061  loss: 0.5730 (0.5726)  time: 5.6977  data: 0.0087  max mem: 22633
[04:28:47.556541] Epoch: [2]  [  80/1527]  eta: 2:22:45  lr: 0.000062  loss: 0.5676 (0.5720)  time: 6.3891  data: 0.0004  max mem: 22633
[04:30:45.695202] Epoch: [2]  [ 100/1527]  eta: 2:20:43  lr: 0.000062  loss: 0.5639 (0.5708)  time: 5.9068  data: 0.0128  max mem: 22633
[04:32:42.239451] Epoch: [2]  [ 120/1527]  eta: 2:18:24  lr: 0.000062  loss: 0.5631 (0.5697)  time: 5.8271  data: 0.0225  max mem: 22633
[04:34:49.225272] Epoch: [2]  [ 140/1527]  eta: 2:17:54  lr: 0.000063  loss: 0.5624 (0.5690)  time: 6.3492  data: 0.0023  max mem: 22633
[04:36:41.487067] Epoch: [2]  [ 160/1527]  eta: 2:14:55  lr: 0.000063  loss: 0.5629 (0.5684)  time: 5.6130  data: 0.0152  max mem: 22633
[04:38:36.993870] Epoch: [2]  [ 180/1527]  eta: 2:12:34  lr: 0.000064  loss: 0.5624 (0.5680)  time: 5.7752  data: 1.1326  max mem: 22633
[04:40:33.457319] Epoch: [2]  [ 200/1527]  eta: 2:10:25  lr: 0.000064  loss: 0.5608 (0.5675)  time: 5.8231  data: 0.4254  max mem: 22633
[04:42:27.739418] Epoch: [2]  [ 220/1527]  eta: 2:08:06  lr: 0.000064  loss: 0.5589 (0.5669)  time: 5.7140  data: 0.0003  max mem: 22633
[04:44:09.265474] Epoch: [2]  [ 240/1527]  eta: 2:04:42  lr: 0.000065  loss: 0.5602 (0.5664)  time: 5.0762  data: 0.0006  max mem: 22633
[04:46:02.910877] Epoch: [2]  [ 260/1527]  eta: 2:02:33  lr: 0.000065  loss: 0.5581 (0.5659)  time: 5.6822  data: 0.0003  max mem: 22633
[04:48:11.044583] Epoch: [2]  [ 280/1527]  eta: 2:01:31  lr: 0.000066  loss: 0.5532 (0.5651)  time: 6.4066  data: 0.0003  max mem: 22633
[04:50:07.450930] Epoch: [2]  [ 300/1527]  eta: 1:59:31  lr: 0.000066  loss: 0.5519 (0.5644)  time: 5.8203  data: 0.0003  max mem: 22633
[04:52:04.923761] Epoch: [2]  [ 320/1527]  eta: 1:57:37  lr: 0.000066  loss: 0.5572 (0.5639)  time: 5.8736  data: 0.0003  max mem: 22633
[04:54:04.597200] Epoch: [2]  [ 340/1527]  eta: 1:55:49  lr: 0.000067  loss: 0.5579 (0.5635)  time: 5.9836  data: 0.0003  max mem: 22633
[04:56:11.801805] Epoch: [2]  [ 360/1527]  eta: 1:54:25  lr: 0.000067  loss: 0.5479 (0.5627)  time: 6.3601  data: 0.0003  max mem: 22633
[04:58:13.886513] Epoch: [2]  [ 380/1527]  eta: 1:52:41  lr: 0.000067  loss: 0.5427 (0.5619)  time: 6.1042  data: 0.0004  max mem: 22633
[05:00:08.244241] Epoch: [2]  [ 400/1527]  eta: 1:50:33  lr: 0.000068  loss: 0.5503 (0.5614)  time: 5.7178  data: 0.0086  max mem: 22633
[05:01:53.800119] Epoch: [2]  [ 420/1527]  eta: 1:48:03  lr: 0.000068  loss: 0.5483 (0.5607)  time: 5.2777  data: 0.0565  max mem: 22633
[05:04:01.280690] Epoch: [2]  [ 440/1527]  eta: 1:46:31  lr: 0.000069  loss: 0.5458 (0.5601)  time: 6.3740  data: 0.0519  max mem: 22633
[05:06:06.806717] Epoch: [2]  [ 460/1527]  eta: 1:44:52  lr: 0.000069  loss: 0.5414 (0.5593)  time: 6.2762  data: 0.0246  max mem: 22633
[05:07:50.808911] Epoch: [2]  [ 480/1527]  eta: 1:42:24  lr: 0.000069  loss: 0.5414 (0.5587)  time: 5.2000  data: 0.0198  max mem: 22633
[05:09:53.158065] Epoch: [2]  [ 500/1527]  eta: 1:40:37  lr: 0.000070  loss: 0.5420 (0.5580)  time: 6.1174  data: 0.0417  max mem: 22633
[05:11:40.981647] Epoch: [2]  [ 520/1527]  eta: 1:38:20  lr: 0.000070  loss: 0.5408 (0.5574)  time: 5.3911  data: 0.0287  max mem: 22633
[05:13:33.935945] Epoch: [2]  [ 540/1527]  eta: 1:36:15  lr: 0.000071  loss: 0.5390 (0.5568)  time: 5.6476  data: 0.0735  max mem: 22633
[05:15:27.218608] Epoch: [2]  [ 560/1527]  eta: 1:34:12  lr: 0.000071  loss: 0.5379 (0.5562)  time: 5.6640  data: 0.0746  max mem: 22633
[05:17:28.620290] Epoch: [2]  [ 580/1527]  eta: 1:32:22  lr: 0.000071  loss: 0.5349 (0.5555)  time: 6.0700  data: 0.0562  max mem: 22633
[05:19:32.670731] Epoch: [2]  [ 600/1527]  eta: 1:30:36  lr: 0.000072  loss: 0.5365 (0.5549)  time: 6.2025  data: 0.0126  max mem: 22633
[05:21:32.566406] Epoch: [2]  [ 620/1527]  eta: 1:28:42  lr: 0.000072  loss: 0.5344 (0.5542)  time: 5.9945  data: 0.0178  max mem: 22633
[05:23:37.165969] Epoch: [2]  [ 640/1527]  eta: 1:26:55  lr: 0.000073  loss: 0.5312 (0.5535)  time: 6.2299  data: 0.0159  max mem: 22633
[05:25:26.583508] Epoch: [2]  [ 660/1527]  eta: 1:24:47  lr: 0.000073  loss: 0.5339 (0.5529)  time: 5.4708  data: 0.0064  max mem: 22633
[05:27:20.459711] Epoch: [2]  [ 680/1527]  eta: 1:22:45  lr: 0.000073  loss: 0.5283 (0.5522)  time: 5.6937  data: 0.0301  max mem: 22633
[05:29:25.879351] Epoch: [2]  [ 700/1527]  eta: 1:20:57  lr: 0.000074  loss: 0.5301 (0.5517)  time: 6.2706  data: 0.1537  max mem: 22633
[05:31:27.536743] Epoch: [2]  [ 720/1527]  eta: 1:19:05  lr: 0.000074  loss: 0.5267 (0.5510)  time: 6.0824  data: 0.0248  max mem: 22633
[05:33:13.237671] Epoch: [2]  [ 740/1527]  eta: 1:16:54  lr: 0.000075  loss: 0.5267 (0.5503)  time: 5.2850  data: 0.0124  max mem: 22633
[05:35:08.207148] Epoch: [2]  [ 760/1527]  eta: 1:14:55  lr: 0.000075  loss: 0.5240 (0.5496)  time: 5.7484  data: 0.0172  max mem: 22633
[05:37:05.491807] Epoch: [2]  [ 780/1527]  eta: 1:12:58  lr: 0.000075  loss: 0.5209 (0.5489)  time: 5.8642  data: 0.0308  max mem: 22633
[05:39:15.809754] Epoch: [2]  [ 800/1527]  eta: 1:11:12  lr: 0.000076  loss: 0.5246 (0.5484)  time: 6.5158  data: 0.0004  max mem: 22633
[05:41:08.962273] Epoch: [2]  [ 820/1527]  eta: 1:09:11  lr: 0.000076  loss: 0.5213 (0.5478)  time: 5.6575  data: 0.0004  max mem: 22633
[05:43:06.537477] Epoch: [2]  [ 840/1527]  eta: 1:07:14  lr: 0.000077  loss: 0.5182 (0.5471)  time: 5.8787  data: 0.0004  max mem: 22633
[05:45:01.372957] Epoch: [2]  [ 860/1527]  eta: 1:05:14  lr: 0.000077  loss: 0.5141 (0.5463)  time: 5.7417  data: 0.0003  max mem: 22633
[05:47:04.398147] Epoch: [2]  [ 880/1527]  eta: 1:03:21  lr: 0.000077  loss: 0.5127 (0.5456)  time: 6.1512  data: 0.0004  max mem: 22633
[05:49:05.362726] Epoch: [2]  [ 900/1527]  eta: 1:01:26  lr: 0.000078  loss: 0.5128 (0.5449)  time: 6.0482  data: 0.0004  max mem: 22633
[05:51:05.747403] Epoch: [2]  [ 920/1527]  eta: 0:59:30  lr: 0.000078  loss: 0.5143 (0.5443)  time: 6.0192  data: 0.0003  max mem: 22633
[05:52:47.866040] Epoch: [2]  [ 940/1527]  eta: 0:57:23  lr: 0.000078  loss: 0.5087 (0.5435)  time: 5.1059  data: 0.0003  max mem: 22633
[05:54:42.508737] Epoch: [2]  [ 960/1527]  eta: 0:55:24  lr: 0.000079  loss: 0.5085 (0.5428)  time: 5.7317  data: 0.0003  max mem: 22633
[05:56:34.313290] Epoch: [2]  [ 980/1527]  eta: 0:53:24  lr: 0.000079  loss: 0.5056 (0.5421)  time: 5.5902  data: 0.0003  max mem: 22633
[05:58:25.941653] Epoch: [2]  [1000/1527]  eta: 0:51:23  lr: 0.000080  loss: 0.5070 (0.5414)  time: 5.5814  data: 0.0003  max mem: 22633
[06:00:32.630661] Epoch: [2]  [1020/1527]  eta: 0:49:31  lr: 0.000080  loss: 0.5049 (0.5407)  time: 6.3344  data: 0.0004  max mem: 22633
[06:02:16.954503] Epoch: [2]  [1040/1527]  eta: 0:47:28  lr: 0.000080  loss: 0.5048 (0.5401)  time: 5.2161  data: 0.0003  max mem: 22633
[06:04:08.952370] Epoch: [2]  [1060/1527]  eta: 0:45:29  lr: 0.000081  loss: 0.5011 (0.5394)  time: 5.5998  data: 0.0003  max mem: 22633
[06:06:07.396783] Epoch: [2]  [1080/1527]  eta: 0:43:33  lr: 0.000081  loss: 0.4991 (0.5386)  time: 5.9221  data: 0.0002  max mem: 22633
[06:08:04.215991] Epoch: [2]  [1100/1527]  eta: 0:41:36  lr: 0.000082  loss: 0.5005 (0.5380)  time: 5.8409  data: 0.0003  max mem: 22633
[06:09:59.720024] Epoch: [2]  [1120/1527]  eta: 0:39:38  lr: 0.000082  loss: 0.5006 (0.5373)  time: 5.7751  data: 0.0002  max mem: 22633
[06:11:59.369422] Epoch: [2]  [1140/1527]  eta: 0:37:42  lr: 0.000082  loss: 0.4958 (0.5366)  time: 5.9824  data: 0.1468  max mem: 22633
[06:13:57.851350] Epoch: [2]  [1160/1527]  eta: 0:35:46  lr: 0.000083  loss: 0.4926 (0.5358)  time: 5.9240  data: 0.6556  max mem: 22633
[06:16:01.277022] Epoch: [2]  [1180/1527]  eta: 0:33:51  lr: 0.000083  loss: 0.4964 (0.5351)  time: 6.1712  data: 1.8799  max mem: 22633
[06:18:01.584296] Epoch: [2]  [1200/1527]  eta: 0:31:55  lr: 0.000084  loss: 0.4861 (0.5344)  time: 6.0153  data: 2.5771  max mem: 22633
[06:20:04.930610] Epoch: [2]  [1220/1527]  eta: 0:29:59  lr: 0.000084  loss: 0.4869 (0.5336)  time: 6.1670  data: 3.5443  max mem: 22633
[06:21:57.629810] Epoch: [2]  [1240/1527]  eta: 0:28:01  lr: 0.000084  loss: 0.4893 (0.5329)  time: 5.6349  data: 3.3384  max mem: 22633
[06:23:57.199011] Epoch: [2]  [1260/1527]  eta: 0:26:04  lr: 0.000085  loss: 0.4841 (0.5322)  time: 5.9784  data: 3.8172  max mem: 22633

[06:25:58.259014] Epoch: [2]  [1280/1527]  eta: 0:24:08  lr: 0.000085  loss: 0.4845 (0.5314)  time: 6.0529  data: 3.3349  max mem: 22633
[06:27:53.578459] Epoch: [2]  [1300/1527]  eta: 0:22:10  lr: 0.000086  loss: 0.4789 (0.5307)  time: 5.7659  data: 3.1469  max mem: 22633
[06:29:51.909537] Epoch: [2]  [1320/1527]  eta: 0:20:13  lr: 0.000086  loss: 0.4837 (0.5300)  time: 5.9165  data: 2.2723  max mem: 22633
[06:31:54.357426] Epoch: [2]  [1340/1527]  eta: 0:18:16  lr: 0.000086  loss: 0.4782 (0.5292)  time: 6.1223  data: 0.9436  max mem: 22633
[06:33:48.634294] Epoch: [2]  [1360/1527]  eta: 0:16:19  lr: 0.000087  loss: 0.4750 (0.5284)  time: 5.7138  data: 0.5007  max mem: 22633
[06:35:41.806570] Epoch: [2]  [1380/1527]  eta: 0:14:21  lr: 0.000087  loss: 0.4752 (0.5277)  time: 5.6585  data: 1.6648  max mem: 22633
[06:37:41.727108] Epoch: [2]  [1400/1527]  eta: 0:12:24  lr: 0.000088  loss: 0.4717 (0.5269)  time: 5.9960  data: 2.0238  max mem: 22633
[06:39:43.580983] Epoch: [2]  [1420/1527]  eta: 0:10:27  lr: 0.000088  loss: 0.4712 (0.5261)  time: 6.0926  data: 1.5949  max mem: 22633
[06:41:41.767684] Epoch: [2]  [1440/1527]  eta: 0:08:30  lr: 0.000088  loss: 0.4714 (0.5254)  time: 5.9093  data: 1.0394  max mem: 22633
[06:43:37.306225] Epoch: [2]  [1460/1527]  eta: 0:06:32  lr: 0.000089  loss: 0.4639 (0.5246)  time: 5.7768  data: 0.9730  max mem: 22633
[06:45:27.870686] Epoch: [2]  [1480/1527]  eta: 0:04:35  lr: 0.000089  loss: 0.4658 (0.5239)  time: 5.5282  data: 0.3457  max mem: 22633
[06:47:26.524616] Epoch: [2]  [1500/1527]  eta: 0:02:38  lr: 0.000089  loss: 0.4684 (0.5232)  time: 5.9326  data: 0.0003  max mem: 22633
[06:49:32.191156] Epoch: [2]  [1520/1527]  eta: 0:00:41  lr: 0.000090  loss: 0.4632 (0.5224)  time: 6.2832  data: 0.0011  max mem: 22633
[06:51:45.823390] Epoch: [2]  [1526/1527]  eta: 0:00:05  lr: 0.000090  loss: 0.4624 (0.5222)  time: 10.4910  data: 0.0010  max mem: 22633
[06:51:46.155744] Epoch: [2] Total time: 2:30:58 (5.9320 s / it)
[06:51:46.206984] Averaged stats: lr: 0.000090  loss: 0.4624 (0.5221)
[06:51:46.211680] log_dir: /proj/cloudrobotics-nest/users/Stacking/dataset/CloudGripper_push_1k/pre_trained_weights/vit_base_single_node_s_d
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[06:52:44.994258] torch.Size([256, 3, 224, 224])
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[06:54:12.259350] Epoch: [3]  [   0/1527]  eta: 1 day, 2:23:18  lr: 0.000090  loss: 0.4594 (0.4594)  time: 62.2128  data: 30.7582  max mem: 22633
[06:55:53.750683] Epoch: [3]  [  20/1527]  eta: 3:15:47  lr: 0.000090  loss: 0.4610 (0.4617)  time: 5.0745  data: 1.0118  max mem: 22633
[06:57:49.419711] Epoch: [3]  [  40/1527]  eta: 2:48:52  lr: 0.000091  loss: 0.4571 (0.4596)  time: 5.7834  data: 1.4331  max mem: 22633
[06:59:34.353754] Epoch: [3]  [  60/1527]  eta: 2:34:02  lr: 0.000091  loss: 0.4603 (0.4601)  time: 5.2466  data: 2.2100  max mem: 22633
[07:01:23.497640] Epoch: [3]  [  80/1527]  eta: 2:26:54  lr: 0.000092  loss: 0.4503 (0.4596)  time: 5.4571  data: 2.1267  max mem: 22633
[07:03:23.307983] Epoch: [3]  [ 100/1527]  eta: 2:24:24  lr: 0.000092  loss: 0.4554 (0.4593)  time: 5.9904  data: 1.6347  max mem: 22633
[07:05:18.942710] Epoch: [3]  [ 120/1527]  eta: 2:21:15  lr: 0.000092  loss: 0.4504 (0.4580)  time: 5.7817  data: 0.9907  max mem: 22633
[07:07:35.554218] Epoch: [3]  [ 140/1527]  eta: 2:21:53  lr: 0.000093  loss: 0.4497 (0.4567)  time: 6.8305  data: 1.1557  max mem: 22633
[07:09:27.590884] Epoch: [3]  [ 160/1527]  eta: 2:18:19  lr: 0.000093  loss: 0.4477 (0.4560)  time: 5.6018  data: 0.0486  max mem: 22633
[07:11:25.219237] Epoch: [3]  [ 180/1527]  eta: 2:15:50  lr: 0.000094  loss: 0.4472 (0.4557)  time: 5.8813  data: 0.0522  max mem: 22633
[07:13:23.518347] Epoch: [3]  [ 200/1527]  eta: 2:13:31  lr: 0.000094  loss: 0.4483 (0.4550)  time: 5.9149  data: 0.0606  max mem: 22633
[07:15:28.812231] Epoch: [3]  [ 220/1527]  eta: 2:11:57  lr: 0.000094  loss: 0.4441 (0.4541)  time: 6.2646  data: 0.0629  max mem: 22633
[07:17:21.542592] Epoch: [3]  [ 240/1527]  eta: 2:09:11  lr: 0.000095  loss: 0.4438 (0.4532)  time: 5.6364  data: 0.0452  max mem: 22633
[07:19:11.048536] Epoch: [3]  [ 260/1527]  eta: 2:06:17  lr: 0.000095  loss: 0.4408 (0.4524)  time: 5.4752  data: 0.0499  max mem: 22633
[07:21:05.828842] Epoch: [3]  [ 280/1527]  eta: 2:03:56  lr: 0.000096  loss: 0.4405 (0.4515)  time: 5.7389  data: 0.0436  max mem: 22633
[07:22:48.127542] Epoch: [3]  [ 300/1527]  eta: 2:00:48  lr: 0.000096  loss: 0.4351 (0.4505)  time: 5.1148  data: 0.0703  max mem: 22633
[07:24:39.108388] Epoch: [3]  [ 320/1527]  eta: 1:58:22  lr: 0.000096  loss: 0.4376 (0.4499)  time: 5.5485  data: 0.0717  max mem: 22633
[07:26:27.722505] Epoch: [3]  [ 340/1527]  eta: 1:55:53  lr: 0.000097  loss: 0.4356 (0.4491)  time: 5.4306  data: 0.0676  max mem: 22633
[07:28:20.301535] Epoch: [3]  [ 360/1527]  eta: 1:53:41  lr: 0.000097  loss: 0.4314 (0.4481)  time: 5.6289  data: 0.0605  max mem: 22633
[07:30:17.819288] Epoch: [3]  [ 380/1527]  eta: 1:51:46  lr: 0.000097  loss: 0.4319 (0.4474)  time: 5.8758  data: 0.0480  max mem: 22633
[07:32:13.464856] Epoch: [3]  [ 400/1527]  eta: 1:49:45  lr: 0.000098  loss: 0.4302 (0.4465)  time: 5.7822  data: 0.0723  max mem: 22633
[07:34:08.878183] Epoch: [3]  [ 420/1527]  eta: 1:47:45  lr: 0.000098  loss: 0.4269 (0.4457)  time: 5.7706  data: 0.0396  max mem: 22633
[07:36:05.136822] Epoch: [3]  [ 440/1527]  eta: 1:45:47  lr: 0.000099  loss: 0.4273 (0.4448)  time: 5.8128  data: 0.0569  max mem: 22633
[07:38:07.432369] Epoch: [3]  [ 460/1527]  eta: 1:44:03  lr: 0.000099  loss: 0.4237 (0.4440)  time: 6.1147  data: 0.0428  max mem: 22633
[07:39:59.991572] Epoch: [3]  [ 480/1527]  eta: 1:41:56  lr: 0.000099  loss: 0.4264 (0.4433)  time: 5.6278  data: 0.0351  max mem: 22633
[07:41:52.398478] Epoch: [3]  [ 500/1527]  eta: 1:39:50  lr: 0.000100  loss: 0.4217 (0.4425)  time: 5.6203  data: 0.0340  max mem: 22633
[07:43:52.797226] Epoch: [3]  [ 520/1527]  eta: 1:38:00  lr: 0.000100  loss: 0.4210 (0.4417)  time: 6.0198  data: 0.0402  max mem: 22633
[07:45:48.670054] Epoch: [3]  [ 540/1527]  eta: 1:36:02  lr: 0.000101  loss: 0.4232 (0.4411)  time: 5.7932  data: 0.0072  max mem: 22633
[07:47:52.805240] Epoch: [3]  [ 560/1527]  eta: 1:34:18  lr: 0.000101  loss: 0.4165 (0.4403)  time: 6.2067  data: 0.0003  max mem: 22633
[07:49:43.859363] Epoch: [3]  [ 580/1527]  eta: 1:32:11  lr: 0.000101  loss: 0.4161 (0.4396)  time: 5.5526  data: 0.0004  max mem: 22633
[07:51:38.159084] Epoch: [3]  [ 600/1527]  eta: 1:30:10  lr: 0.000102  loss: 0.4216 (0.4390)  time: 5.7149  data: 0.0003  max mem: 22633
[07:53:38.402074] Epoch: [3]  [ 620/1527]  eta: 1:28:19  lr: 0.000102  loss: 0.4136 (0.4382)  time: 6.0121  data: 0.0003  max mem: 22633
[07:55:30.103204] Epoch: [3]  [ 640/1527]  eta: 1:26:15  lr: 0.000103  loss: 0.4135 (0.4375)  time: 5.5850  data: 0.0003  max mem: 22633
[07:57:21.057573] Epoch: [3]  [ 660/1527]  eta: 1:24:11  lr: 0.000103  loss: 0.4129 (0.4368)  time: 5.5476  data: 0.0170  max mem: 22633
[07:59:24.361285] Epoch: [3]  [ 680/1527]  eta: 1:22:22  lr: 0.000103  loss: 0.4124 (0.4361)  time: 6.1651  data: 0.0150  max mem: 22633
[08:01:29.729686] Epoch: [3]  [ 700/1527]  eta: 1:20:36  lr: 0.000104  loss: 0.4072 (0.4354)  time: 6.2683  data: 0.0171  max mem: 22633
[08:03:32.991135] Epoch: [3]  [ 720/1527]  eta: 1:18:46  lr: 0.000104  loss: 0.4108 (0.4347)  time: 6.1629  data: 0.0314  max mem: 22633
[08:05:35.894650] Epoch: [3]  [ 740/1527]  eta: 1:16:55  lr: 0.000105  loss: 0.4074 (0.4339)  time: 6.1451  data: 0.0271  max mem: 22633
[08:07:32.380408] Epoch: [3]  [ 760/1527]  eta: 1:14:57  lr: 0.000105  loss: 0.4057 (0.4333)  time: 5.8242  data: 0.0551  max mem: 22633
[08:09:20.932919] Epoch: [3]  [ 780/1527]  eta: 1:12:51  lr: 0.000105  loss: 0.4071 (0.4326)  time: 5.4275  data: 0.0303  max mem: 22633
[08:11:09.961454] Epoch: [3]  [ 800/1527]  eta: 1:10:47  lr: 0.000106  loss: 0.4052 (0.4320)  time: 5.4513  data: 0.0134  max mem: 22633
[08:13:06.960301] Epoch: [3]  [ 820/1527]  eta: 1:08:50  lr: 0.000106  loss: 0.4050 (0.4313)  time: 5.8499  data: 0.0202  max mem: 22633
[08:14:53.288660] Epoch: [3]  [ 840/1527]  eta: 1:06:45  lr: 0.000107  loss: 0.4033 (0.4306)  time: 5.3164  data: 0.0176  max mem: 22633
[08:16:42.476931] Epoch: [3]  [ 860/1527]  eta: 1:04:42  lr: 0.000107  loss: 0.4033 (0.4300)  time: 5.4594  data: 0.0062  max mem: 22633
[08:18:37.132928] Epoch: [3]  [ 880/1527]  eta: 1:02:45  lr: 0.000107  loss: 0.3997 (0.4293)  time: 5.7326  data: 0.1306  max mem: 22633
[08:20:45.249052] Epoch: [3]  [ 900/1527]  eta: 1:00:56  lr: 0.000108  loss: 0.3959 (0.4286)  time: 6.4057  data: 0.0042  max mem: 22633
[08:22:39.173091] Epoch: [3]  [ 920/1527]  eta: 0:58:58  lr: 0.000108  loss: 0.3994 (0.4280)  time: 5.6961  data: 0.0003  max mem: 22633
[08:24:47.712970] Epoch: [3]  [ 940/1527]  eta: 0:57:09  lr: 0.000108  loss: 0.3961 (0.4274)  time: 6.4269  data: 0.0004  max mem: 22633
[08:26:43.267355] Epoch: [3]  [ 960/1527]  eta: 0:55:11  lr: 0.000109  loss: 0.3974 (0.4268)  time: 5.7776  data: 0.0003  max mem: 22633
[08:28:36.699424] Epoch: [3]  [ 980/1527]  eta: 0:53:13  lr: 0.000109  loss: 0.3948 (0.4262)  time: 5.6715  data: 0.0005  max mem: 22633
[08:30:38.139713] Epoch: [3]  [1000/1527]  eta: 0:51:18  lr: 0.000110  loss: 0.3950 (0.4256)  time: 6.0719  data: 0.0003  max mem: 22633
[08:32:36.682392] Epoch: [3]  [1020/1527]  eta: 0:49:22  lr: 0.000110  loss: 0.3915 (0.4249)  time: 5.9271  data: 0.0004  max mem: 22633
[08:34:21.417663] Epoch: [3]  [1040/1527]  eta: 0:47:20  lr: 0.000110  loss: 0.3918 (0.4244)  time: 5.2367  data: 0.0003  max mem: 22633
[08:36:24.278577] Epoch: [3]  [1060/1527]  eta: 0:45:26  lr: 0.000111  loss: 0.3898 (0.4238)  time: 6.1430  data: 0.0004  max mem: 22633
[08:38:11.776003] Epoch: [3]  [1080/1527]  eta: 0:43:25  lr: 0.000111  loss: 0.3936 (0.4232)  time: 5.3748  data: 0.0003  max mem: 22633
[08:40:03.438377] Epoch: [3]  [1100/1527]  eta: 0:41:27  lr: 0.000112  loss: 0.3880 (0.4226)  time: 5.5830  data: 0.0005  max mem: 22633
[08:41:52.040224] Epoch: [3]  [1120/1527]  eta: 0:39:27  lr: 0.000112  loss: 0.3896 (0.4220)  time: 5.4300  data: 0.0003  max mem: 22633
[08:43:44.129373] Epoch: [3]  [1140/1527]  eta: 0:37:30  lr: 0.000112  loss: 0.3871 (0.4215)  time: 5.6044  data: 0.0004  max mem: 22633
[08:45:33.558627] Epoch: [3]  [1160/1527]  eta: 0:35:31  lr: 0.000113  loss: 0.3872 (0.4209)  time: 5.4714  data: 0.0004  max mem: 22633
[08:47:36.126476] Epoch: [3]  [1180/1527]  eta: 0:33:37  lr: 0.000113  loss: 0.3818 (0.4202)  time: 6.1280  data: 0.0004  max mem: 22633
[08:49:31.092356] Epoch: [3]  [1200/1527]  eta: 0:31:40  lr: 0.000114  loss: 0.3846 (0.4197)  time: 5.7481  data: 0.0004  max mem: 22633
[08:51:26.294202] Epoch: [3]  [1220/1527]  eta: 0:29:44  lr: 0.000114  loss: 0.3834 (0.4191)  time: 5.7600  data: 0.0004  max mem: 22633
[08:53:22.241939] Epoch: [3]  [1240/1527]  eta: 0:27:47  lr: 0.000114  loss: 0.3795 (0.4185)  time: 5.7973  data: 0.0004  max mem: 22633
[08:55:27.790600] Epoch: [3]  [1260/1527]  eta: 0:25:53  lr: 0.000115  loss: 0.3844 (0.4180)  time: 6.2774  data: 0.0004  max mem: 22633
[08:57:27.933130] Epoch: [3]  [1280/1527]  eta: 0:23:57  lr: 0.000115  loss: 0.3772 (0.4174)  time: 6.0071  data: 0.0874  max mem: 22633
[08:59:32.354871] Epoch: [3]  [1300/1527]  eta: 0:22:02  lr: 0.000116  loss: 0.3821 (0.4168)  time: 6.2210  data: 0.3356  max mem: 22633
[09:01:47.957852] Epoch: [3]  [1320/1527]  eta: 0:20:09  lr: 0.000116  loss: 0.3802 (0.4163)  time: 6.7801  data: 0.1963  max mem: 22633
[09:03:34.209553] Epoch: [3]  [1340/1527]  eta: 0:18:11  lr: 0.000116  loss: 0.3773 (0.4157)  time: 5.3125  data: 0.6480  max mem: 22633
[09:05:35.281013] Epoch: [3]  [1360/1527]  eta: 0:16:14  lr: 0.000117  loss: 0.3748 (0.4151)  time: 6.0535  data: 0.0323  max mem: 22633
[09:07:39.075116] Epoch: [3]  [1380/1527]  eta: 0:14:18  lr: 0.000117  loss: 0.3745 (0.4146)  time: 6.1896  data: 0.0003  max mem: 22633
[09:09:34.569108] Epoch: [3]  [1400/1527]  eta: 0:12:21  lr: 0.000118  loss: 0.3760 (0.4141)  time: 5.7746  data: 0.0122  max mem: 22633
[09:11:15.414895] Epoch: [3]  [1420/1527]  eta: 0:10:23  lr: 0.000118  loss: 0.3778 (0.4136)  time: 5.0422  data: 0.0135  max mem: 22633
[09:13:03.069303] Epoch: [3]  [1440/1527]  eta: 0:08:26  lr: 0.000118  loss: 0.3785 (0.4131)  time: 5.3827  data: 0.0132  max mem: 22633
[09:14:57.107592] Epoch: [3]  [1460/1527]  eta: 0:06:30  lr: 0.000119  loss: 0.3731 (0.4125)  time: 5.7014  data: 0.0003  max mem: 22633
[09:16:54.491794] Epoch: [3]  [1480/1527]  eta: 0:04:33  lr: 0.000119  loss: 0.3683 (0.4120)  time: 5.8691  data: 0.0003  max mem: 22633
[09:18:55.822963] Epoch: [3]  [1500/1527]  eta: 0:02:37  lr: 0.000119  loss: 0.3729 (0.4115)  time: 6.0665  data: 0.0003  max mem: 22633
[09:21:09.182973] Epoch: [3]  [1520/1527]  eta: 0:00:40  lr: 0.000120  loss: 0.3706 (0.4110)  time: 6.6677  data: 0.0041  max mem: 22633
[09:23:21.757941] Epoch: [3]  [1526/1527]  eta: 0:00:05  lr: 0.000120  loss: 0.3683 (0.4108)  time: 11.0814  data: 0.0040  max mem: 22633
[09:23:21.988725] Epoch: [3] Total time: 2:30:11 (5.9017 s / it)
[09:23:22.063830] Averaged stats: lr: 0.000120  loss: 0.3683 (0.4110)
[09:23:22.068359] log_dir: /proj/cloudrobotics-nest/users/Stacking/dataset/CloudGripper_push_1k/pre_trained_weights/vit_base_single_node_s_d
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[09:24:23.679678] torch.Size([256, 3, 224, 224])
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[09:25:42.552296] Epoch: [4]  [   0/1527]  eta: 20:40:28  lr: 0.000120  loss: 0.3757 (0.3757)  time: 48.7414  data: 30.3647  max mem: 22633
[09:27:04.131049] Epoch: [4]  [  20/1527]  eta: 2:35:51  lr: 0.000120  loss: 0.3688 (0.3693)  time: 4.0789  data: 1.1431  max mem: 22633
[09:28:58.357335] Epoch: [4]  [  40/1527]  eta: 2:27:49  lr: 0.000121  loss: 0.3698 (0.3700)  time: 5.7112  data: 1.4893  max mem: 22633
[09:30:49.970692] Epoch: [4]  [  60/1527]  eta: 2:22:44  lr: 0.000121  loss: 0.3667 (0.3691)  time: 5.5799  data: 1.3540  max mem: 22633
[09:32:48.395367] Epoch: [4]  [  80/1527]  eta: 2:21:17  lr: 0.000122  loss: 0.3696 (0.3694)  time: 5.9211  data: 0.6425  max mem: 22633
[09:34:42.533619] Epoch: [4]  [ 100/1527]  eta: 2:18:37  lr: 0.000122  loss: 0.3651 (0.3687)  time: 5.7068  data: 1.0911  max mem: 22633
[09:36:39.077584] Epoch: [4]  [ 120/1527]  eta: 2:16:40  lr: 0.000122  loss: 0.3606 (0.3680)  time: 5.8271  data: 1.1253  max mem: 22633
[09:38:36.368123] Epoch: [4]  [ 140/1527]  eta: 2:14:51  lr: 0.000123  loss: 0.3655 (0.3679)  time: 5.8645  data: 1.1873  max mem: 22633
[09:40:36.528409] Epoch: [4]  [ 160/1527]  eta: 2:13:24  lr: 0.000123  loss: 0.3641 (0.3677)  time: 6.0079  data: 2.2998  max mem: 22633
[09:42:35.858996] Epoch: [4]  [ 180/1527]  eta: 2:11:43  lr: 0.000124  loss: 0.3639 (0.3676)  time: 5.9665  data: 2.0275  max mem: 22633
[09:44:36.856948] Epoch: [4]  [ 200/1527]  eta: 2:10:10  lr: 0.000124  loss: 0.3630 (0.3672)  time: 6.0498  data: 3.0162  max mem: 22633
[09:46:35.126678] Epoch: [4]  [ 220/1527]  eta: 2:08:15  lr: 0.000124  loss: 0.3596 (0.3668)  time: 5.9134  data: 2.2882  max mem: 22633
[09:48:30.698720] Epoch: [4]  [ 240/1527]  eta: 2:06:06  lr: 0.000125  loss: 0.3609 (0.3665)  time: 5.7785  data: 2.7459  max mem: 22633
[09:50:23.729362] Epoch: [4]  [ 260/1527]  eta: 2:03:46  lr: 0.000125  loss: 0.3604 (0.3660)  time: 5.6515  data: 2.6725  max mem: 22633
[09:52:20.099721] Epoch: [4]  [ 280/1527]  eta: 2:01:45  lr: 0.000126  loss: 0.3620 (0.3658)  time: 5.8183  data: 1.3074  max mem: 22633
[09:54:13.214560] Epoch: [4]  [ 300/1527]  eta: 1:59:31  lr: 0.000126  loss: 0.3620 (0.3655)  time: 5.6557  data: 1.9045  max mem: 22633
[09:56:13.779888] Epoch: [4]  [ 320/1527]  eta: 1:57:48  lr: 0.000126  loss: 0.3549 (0.3649)  time: 6.0282  data: 2.0901  max mem: 22633
[09:58:15.465071] Epoch: [4]  [ 340/1527]  eta: 1:56:07  lr: 0.000127  loss: 0.3584 (0.3647)  time: 6.0842  data: 2.5880  max mem: 22633
[09:59:57.745194] Epoch: [4]  [ 360/1527]  eta: 1:53:21  lr: 0.000127  loss: 0.3568 (0.3643)  time: 5.1139  data: 1.3435  max mem: 22633
[10:01:57.546399] Epoch: [4]  [ 380/1527]  eta: 1:51:34  lr: 0.000127  loss: 0.3550 (0.3639)  time: 5.9900  data: 0.4935  max mem: 22633
[10:03:49.353689] Epoch: [4]  [ 400/1527]  eta: 1:49:23  lr: 0.000128  loss: 0.3573 (0.3637)  time: 5.5903  data: 0.1596  max mem: 22633
[10:06:08.750500] Epoch: [4]  [ 420/1527]  eta: 1:48:27  lr: 0.000128  loss: 0.3572 (0.3635)  time: 6.9698  data: 0.0003  max mem: 22633
[10:08:02.814599] Epoch: [4]  [ 440/1527]  eta: 1:46:21  lr: 0.000129  loss: 0.3531 (0.3632)  time: 5.7031  data: 0.0003  max mem: 22633
[10:09:54.798449] Epoch: [4]  [ 460/1527]  eta: 1:44:11  lr: 0.000129  loss: 0.3533 (0.3628)  time: 5.5991  data: 0.0042  max mem: 22633
[10:11:41.418390] Epoch: [4]  [ 480/1527]  eta: 1:41:51  lr: 0.000129  loss: 0.3480 (0.3623)  time: 5.3309  data: 0.0267  max mem: 22633
[10:13:46.334947] Epoch: [4]  [ 500/1527]  eta: 1:40:11  lr: 0.000130  loss: 0.3506 (0.3620)  time: 6.2457  data: 0.0276  max mem: 22633
[10:15:58.099333] Epoch: [4]  [ 520/1527]  eta: 1:38:42  lr: 0.000130  loss: 0.3511 (0.3616)  time: 6.5882  data: 0.0358  max mem: 22633
[10:17:39.885655] Epoch: [4]  [ 540/1527]  eta: 1:36:16  lr: 0.000131  loss: 0.3448 (0.3611)  time: 5.0893  data: 0.0217  max mem: 22633
[10:19:38.427610] Epoch: [4]  [ 560/1527]  eta: 1:34:21  lr: 0.000131  loss: 0.3524 (0.3608)  time: 5.9270  data: 0.0263  max mem: 22633
[10:21:42.711184] Epoch: [4]  [ 580/1527]  eta: 1:32:36  lr: 0.000131  loss: 0.3462 (0.3603)  time: 6.2141  data: 0.0133  max mem: 22633
[10:23:34.047168] Epoch: [4]  [ 600/1527]  eta: 1:30:29  lr: 0.000132  loss: 0.3473 (0.3599)  time: 5.5667  data: 0.0004  max mem: 22633
[10:25:23.657226] Epoch: [4]  [ 620/1527]  eta: 1:28:21  lr: 0.000132  loss: 0.3452 (0.3596)  time: 5.4804  data: 0.0004  max mem: 22633
[10:27:15.736072] Epoch: [4]  [ 640/1527]  eta: 1:26:17  lr: 0.000133  loss: 0.3445 (0.3591)  time: 5.6038  data: 0.0042  max mem: 22633
[10:29:23.692810] Epoch: [4]  [ 660/1527]  eta: 1:24:35  lr: 0.000133  loss: 0.3449 (0.3587)  time: 6.3978  data: 0.6535  max mem: 22633
[10:31:20.763758] Epoch: [4]  [ 680/1527]  eta: 1:22:38  lr: 0.000133  loss: 0.3421 (0.3583)  time: 5.8535  data: 0.8685  max mem: 22633
[10:33:29.495900] Epoch: [4]  [ 700/1527]  eta: 1:20:55  lr: 0.000134  loss: 0.3454 (0.3579)  time: 6.4365  data: 1.0275  max mem: 22633
[10:35:25.659167] Epoch: [4]  [ 720/1527]  eta: 1:18:56  lr: 0.000134  loss: 0.3436 (0.3575)  time: 5.8081  data: 0.0004  max mem: 22633
[10:37:20.265785] Epoch: [4]  [ 740/1527]  eta: 1:16:56  lr: 0.000135  loss: 0.3446 (0.3572)  time: 5.7301  data: 0.0040  max mem: 22633
[10:39:23.064773] Epoch: [4]  [ 760/1527]  eta: 1:15:04  lr: 0.000135  loss: 0.3383 (0.3568)  time: 6.1398  data: 0.0047  max mem: 22633
[10:41:32.169605] Epoch: [4]  [ 780/1527]  eta: 1:13:18  lr: 0.000135  loss: 0.3420 (0.3565)  time: 6.4552  data: 0.0004  max mem: 22633
[10:43:24.593941] Epoch: [4]  [ 800/1527]  eta: 1:11:15  lr: 0.000136  loss: 0.3370 (0.3560)  time: 5.6212  data: 0.0002  max mem: 22633
[10:45:16.434325] Epoch: [4]  [ 820/1527]  eta: 1:09:12  lr: 0.000136  loss: 0.3431 (0.3557)  time: 5.5919  data: 0.0004  max mem: 22633
[10:47:09.576117] Epoch: [4]  [ 840/1527]  eta: 1:07:11  lr: 0.000137  loss: 0.3379 (0.3553)  time: 5.6566  data: 0.0040  max mem: 22633
[10:49:06.071887] Epoch: [4]  [ 860/1527]  eta: 1:05:13  lr: 0.000137  loss: 0.3379 (0.3550)  time: 5.8235  data: 0.0341  max mem: 22633
[10:51:03.529942] Epoch: [4]  [ 880/1527]  eta: 1:03:16  lr: 0.000137  loss: 0.3346 (0.3545)  time: 5.8728  data: 0.9780  max mem: 22633
[10:53:03.220530] Epoch: [4]  [ 900/1527]  eta: 1:01:20  lr: 0.000138  loss: 0.3409 (0.3542)  time: 5.9844  data: 0.9475  max mem: 22633
[10:54:58.368652] Epoch: [4]  [ 920/1527]  eta: 0:59:21  lr: 0.000138  loss: 0.3367 (0.3539)  time: 5.7573  data: 1.4296  max mem: 22633
[10:56:55.229187] Epoch: [4]  [ 940/1527]  eta: 0:57:24  lr: 0.000138  loss: 0.3350 (0.3535)  time: 5.8429  data: 1.0653  max mem: 22633
[10:58:58.389763] Epoch: [4]  [ 960/1527]  eta: 0:55:30  lr: 0.000139  loss: 0.3363 (0.3532)  time: 6.1579  data: 0.0927  max mem: 22633
[11:00:47.690225] Epoch: [4]  [ 980/1527]  eta: 0:53:28  lr: 0.000139  loss: 0.3318 (0.3527)  time: 5.4649  data: 0.0099  max mem: 22633
[11:02:40.392188] Epoch: [4]  [1000/1527]  eta: 0:51:28  lr: 0.000140  loss: 0.3364 (0.3524)  time: 5.6350  data: 0.1054  max mem: 22633
[11:04:36.160678] Epoch: [4]  [1020/1527]  eta: 0:49:30  lr: 0.000140  loss: 0.3352 (0.3521)  time: 5.7883  data: 0.9391  max mem: 22633
[11:06:35.058493] Epoch: [4]  [1040/1527]  eta: 0:47:34  lr: 0.000140  loss: 0.3360 (0.3519)  time: 5.9448  data: 1.0284  max mem: 22633
[11:08:35.077030] Epoch: [4]  [1060/1527]  eta: 0:45:38  lr: 0.000141  loss: 0.3335 (0.3515)  time: 6.0008  data: 0.8177  max mem: 22633
[11:10:38.077460] Epoch: [4]  [1080/1527]  eta: 0:43:43  lr: 0.000141  loss: 0.3331 (0.3512)  time: 6.1498  data: 0.0040  max mem: 22633
[11:12:33.183830] Epoch: [4]  [1100/1527]  eta: 0:41:45  lr: 0.000142  loss: 0.3286 (0.3508)  time: 5.7552  data: 0.0041  max mem: 22633
[11:14:21.228531] Epoch: [4]  [1120/1527]  eta: 0:39:44  lr: 0.000142  loss: 0.3316 (0.3505)  time: 5.4022  data: 0.2146  max mem: 22633
[11:16:15.073732] Epoch: [4]  [1140/1527]  eta: 0:37:46  lr: 0.000142  loss: 0.3307 (0.3502)  time: 5.6922  data: 0.3394  max mem: 22633
[11:18:10.690230] Epoch: [4]  [1160/1527]  eta: 0:35:48  lr: 0.000143  loss: 0.3283 (0.3498)  time: 5.7808  data: 0.0070  max mem: 22633
[11:20:00.693468] Epoch: [4]  [1180/1527]  eta: 0:33:49  lr: 0.000143  loss: 0.3282 (0.3495)  time: 5.5001  data: 0.0177  max mem: 22633
[11:21:48.435208] Epoch: [4]  [1200/1527]  eta: 0:31:49  lr: 0.000144  loss: 0.3278 (0.3492)  time: 5.3870  data: 0.0173  max mem: 22633
[11:23:46.557120] Epoch: [4]  [1220/1527]  eta: 0:29:53  lr: 0.000144  loss: 0.3278 (0.3488)  time: 5.9060  data: 0.0353  max mem: 22633
[11:25:34.046905] Epoch: [4]  [1240/1527]  eta: 0:27:54  lr: 0.000144  loss: 0.3272 (0.3485)  time: 5.3744  data: 0.0184  max mem: 22633
[11:27:25.074330] Epoch: [4]  [1260/1527]  eta: 0:25:56  lr: 0.000145  loss: 0.3292 (0.3482)  time: 5.5513  data: 0.3281  max mem: 22633
[11:29:27.074378] Epoch: [4]  [1280/1527]  eta: 0:24:00  lr: 0.000145  loss: 0.3294 (0.3479)  time: 6.0999  data: 1.2698  max mem: 22633
[11:31:20.610041] Epoch: [4]  [1300/1527]  eta: 0:22:03  lr: 0.000146  loss: 0.3217 (0.3475)  time: 5.6767  data: 0.0791  max mem: 22633
[11:33:13.209884] Epoch: [4]  [1320/1527]  eta: 0:20:06  lr: 0.000146  loss: 0.3279 (0.3472)  time: 5.6299  data: 0.0202  max mem: 22633
[11:35:09.818836] Epoch: [4]  [1340/1527]  eta: 0:18:09  lr: 0.000146  loss: 0.3218 (0.3469)  time: 5.8304  data: 0.0165  max mem: 22633
[11:37:09.715524] Epoch: [4]  [1360/1527]  eta: 0:16:13  lr: 0.000147  loss: 0.3242 (0.3466)  time: 5.9691  data: 0.0119  max mem: 22633
[11:39:01.547161] Epoch: [4]  [1380/1527]  eta: 0:14:16  lr: 0.000147  loss: 0.3258 (0.3463)  time: 5.5915  data: 0.0213  max mem: 22633
[11:41:07.743163] Epoch: [4]  [1400/1527]  eta: 0:12:20  lr: 0.000148  loss: 0.3229 (0.3460)  time: 6.3097  data: 0.0133  max mem: 22633
[11:43:08.033991] Epoch: [4]  [1420/1527]  eta: 0:10:24  lr: 0.000148  loss: 0.3184 (0.3456)  time: 6.0145  data: 0.0327  max mem: 22633
[11:44:59.504253] Epoch: [4]  [1440/1527]  eta: 0:08:27  lr: 0.000148  loss: 0.3193 (0.3453)  time: 5.5735  data: 0.0139  max mem: 22633
[11:47:01.876613] Epoch: [4]  [1460/1527]  eta: 0:06:31  lr: 0.000149  loss: 0.3194 (0.3449)  time: 6.1186  data: 0.0003  max mem: 22633
[11:48:59.250246] Epoch: [4]  [1480/1527]  eta: 0:04:34  lr: 0.000149  loss: 0.3173 (0.3447)  time: 5.8686  data: 0.0004  max mem: 22633
[11:51:00.410560] Epoch: [4]  [1500/1527]  eta: 0:02:37  lr: 0.000149  loss: 0.3193 (0.3444)  time: 6.0580  data: 0.0003  max mem: 22633
[11:52:57.604202] Epoch: [4]  [1520/1527]  eta: 0:00:40  lr: 0.000150  loss: 0.3214 (0.3441)  time: 5.8596  data: 0.0024  max mem: 22633
[11:55:53.808057] Epoch: [4]  [1526/1527]  eta: 0:00:05  lr: 0.000150  loss: 0.3190 (0.3440)  time: 12.2115  data: 0.0023  max mem: 22633
[11:55:54.088475] Epoch: [4] Total time: 2:31:00 (5.9334 s / it)
[11:55:54.105367] Averaged stats: lr: 0.000150  loss: 0.3190 (0.3439)
[11:55:54.110401] log_dir: /proj/cloudrobotics-nest/users/Stacking/dataset/CloudGripper_push_1k/pre_trained_weights/vit_base_single_node_s_d
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[11:56:55.315261] torch.Size([256, 3, 224, 224])
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[11:58:07.606552] Epoch: [5]  [   0/1527]  eta: 11:40:10  lr: 0.000150  loss: 0.3128 (0.3128)  time: 27.5116  data: 26.5737  max mem: 22633
[11:59:46.835161] Epoch: [5]  [  20/1527]  eta: 2:31:34  lr: 0.000150  loss: 0.3177 (0.3193)  time: 4.9613  data: 1.9945  max mem: 22633
[12:01:34.292025] Epoch: [5]  [  40/1527]  eta: 2:21:33  lr: 0.000151  loss: 0.3169 (0.3181)  time: 5.3727  data: 1.4684  max mem: 22633
[12:03:29.771662] Epoch: [5]  [  60/1527]  eta: 2:20:09  lr: 0.000151  loss: 0.3135 (0.3172)  time: 5.7738  data: 0.7090  max mem: 22633
[12:05:26.019838] Epoch: [5]  [  80/1527]  eta: 2:18:43  lr: 0.000152  loss: 0.3160 (0.3174)  time: 5.8123  data: 0.0307  max mem: 22633
[12:07:20.375812] Epoch: [5]  [ 100/1527]  eta: 2:16:38  lr: 0.000152  loss: 0.3142 (0.3173)  time: 5.7177  data: 0.1063  max mem: 22633
[12:09:12.348488] Epoch: [5]  [ 120/1527]  eta: 2:14:09  lr: 0.000152  loss: 0.3134 (0.3172)  time: 5.5986  data: 1.6181  max mem: 22633
[12:11:17.420152] Epoch: [5]  [ 140/1527]  eta: 2:13:59  lr: 0.000153  loss: 0.3115 (0.3165)  time: 6.2535  data: 1.1194  max mem: 22633
[12:13:14.643911] Epoch: [5]  [ 160/1527]  eta: 2:12:14  lr: 0.000153  loss: 0.3131 (0.3161)  time: 5.8611  data: 1.6209  max mem: 22633
[12:15:08.446373] Epoch: [5]  [ 180/1527]  eta: 2:10:01  lr: 0.000154  loss: 0.3138 (0.3158)  time: 5.6900  data: 1.1782  max mem: 22633
[12:17:10.738339] Epoch: [5]  [ 200/1527]  eta: 2:08:48  lr: 0.000154  loss: 0.3141 (0.3158)  time: 6.1145  data: 0.9679  max mem: 22633
[12:19:00.992749] Epoch: [5]  [ 220/1527]  eta: 2:06:15  lr: 0.000154  loss: 0.3099 (0.3155)  time: 5.5123  data: 0.0862  max mem: 22633
[12:20:53.301017] Epoch: [5]  [ 240/1527]  eta: 2:03:59  lr: 0.000155  loss: 0.3100 (0.3151)  time: 5.6153  data: 0.5025  max mem: 22633
[12:22:32.763971] Epoch: [5]  [ 260/1527]  eta: 2:00:45  lr: 0.000155  loss: 0.3086 (0.3147)  time: 4.9727  data: 0.2488  max mem: 22633
[12:24:30.782590] Epoch: [5]  [ 280/1527]  eta: 1:59:07  lr: 0.000156  loss: 0.3110 (0.3145)  time: 5.9009  data: 0.7734  max mem: 22633
[12:26:26.018654] Epoch: [5]  [ 300/1527]  eta: 1:57:15  lr: 0.000156  loss: 0.3125 (0.3144)  time: 5.7617  data: 0.7082  max mem: 22633
[12:28:33.333516] Epoch: [5]  [ 320/1527]  eta: 1:56:08  lr: 0.000156  loss: 0.3086 (0.3142)  time: 6.3657  data: 0.2225  max mem: 22633
[12:30:23.449888] Epoch: [5]  [ 340/1527]  eta: 1:53:54  lr: 0.000157  loss: 0.3063 (0.3138)  time: 5.5057  data: 0.0342  max mem: 22633
[12:32:24.404732] Epoch: [5]  [ 360/1527]  eta: 1:52:17  lr: 0.000157  loss: 0.3119 (0.3137)  time: 6.0477  data: 0.1776  max mem: 22633
[12:34:18.574705] Epoch: [5]  [ 380/1527]  eta: 1:50:18  lr: 0.000157  loss: 0.3064 (0.3135)  time: 5.7084  data: 0.1149  max mem: 22633
[12:36:09.223240] Epoch: [5]  [ 400/1527]  eta: 1:48:09  lr: 0.000158  loss: 0.3054 (0.3132)  time: 5.5324  data: 1.7290  max mem: 22633
[12:37:57.972226] Epoch: [5]  [ 420/1527]  eta: 1:45:57  lr: 0.000158  loss: 0.3081 (0.3130)  time: 5.4374  data: 2.3891  max mem: 22633
[12:40:02.219371] Epoch: [5]  [ 440/1527]  eta: 1:44:25  lr: 0.000159  loss: 0.3053 (0.3127)  time: 6.2123  data: 3.7729  max mem: 22633
[12:41:54.015749] Epoch: [5]  [ 460/1527]  eta: 1:42:22  lr: 0.000159  loss: 0.3064 (0.3124)  time: 5.5895  data: 2.4321  max mem: 22633
[12:43:47.067493] Epoch: [5]  [ 480/1527]  eta: 1:40:22  lr: 0.000159  loss: 0.3038 (0.3122)  time: 5.6525  data: 2.8537  max mem: 22633
[12:45:46.958899] Epoch: [5]  [ 500/1527]  eta: 1:38:37  lr: 0.000160  loss: 0.3075 (0.3121)  time: 5.9945  data: 3.1413  max mem: 22633
[12:47:51.890286] Epoch: [5]  [ 520/1527]  eta: 1:37:01  lr: 0.000160  loss: 0.3049 (0.3118)  time: 6.2465  data: 2.3614  max mem: 22633
[12:49:56.942758] Epoch: [5]  [ 540/1527]  eta: 1:35:22  lr: 0.000161  loss: 0.3053 (0.3116)  time: 6.2526  data: 1.6816  max mem: 22633
[12:51:57.172149] Epoch: [5]  [ 560/1527]  eta: 1:33:34  lr: 0.000161  loss: 0.3033 (0.3113)  time: 6.0114  data: 1.7606  max mem: 22633
[12:53:41.915804] Epoch: [5]  [ 580/1527]  eta: 1:31:19  lr: 0.000161  loss: 0.3033 (0.3111)  time: 5.2371  data: 1.0119  max mem: 22633
[12:55:37.154412] Epoch: [5]  [ 600/1527]  eta: 1:29:23  lr: 0.000162  loss: 0.2994 (0.3107)  time: 5.7618  data: 1.6613  max mem: 22633
[12:57:33.492251] Epoch: [5]  [ 620/1527]  eta: 1:27:28  lr: 0.000162  loss: 0.3042 (0.3105)  time: 5.8168  data: 0.7138  max mem: 22633
[12:59:32.153709] Epoch: [5]  [ 640/1527]  eta: 1:25:36  lr: 0.000163  loss: 0.3036 (0.3103)  time: 5.9328  data: 0.7021  max mem: 22633
[13:01:33.513937] Epoch: [5]  [ 660/1527]  eta: 1:23:47  lr: 0.000163  loss: 0.3016 (0.3101)  time: 6.0679  data: 0.0004  max mem: 22633
[13:03:27.208525] Epoch: [5]  [ 680/1527]  eta: 1:21:49  lr: 0.000163  loss: 0.2966 (0.3098)  time: 5.6847  data: 0.4823  max mem: 22633
[13:05:26.551257] Epoch: [5]  [ 700/1527]  eta: 1:19:57  lr: 0.000164  loss: 0.2996 (0.3096)  time: 5.9671  data: 0.7651  max mem: 22633
[13:07:18.303660] Epoch: [5]  [ 720/1527]  eta: 1:17:56  lr: 0.000164  loss: 0.2986 (0.3093)  time: 5.5876  data: 0.0004  max mem: 22633
[13:09:22.044314] Epoch: [5]  [ 740/1527]  eta: 1:16:08  lr: 0.000165  loss: 0.2973 (0.3090)  time: 6.1870  data: 0.2132  max mem: 22633
[13:11:28.661854] Epoch: [5]  [ 760/1527]  eta: 1:14:23  lr: 0.000165  loss: 0.2992 (0.3087)  time: 6.3308  data: 0.1637  max mem: 22633
[13:13:16.253061] Epoch: [5]  [ 780/1527]  eta: 1:12:18  lr: 0.000165  loss: 0.2955 (0.3084)  time: 5.3795  data: 0.6196  max mem: 22633
[13:15:14.349397] Epoch: [5]  [ 800/1527]  eta: 1:10:24  lr: 0.000166  loss: 0.2964 (0.3082)  time: 5.9047  data: 1.4584  max mem: 22633
[13:17:15.967277] Epoch: [5]  [ 820/1527]  eta: 1:08:32  lr: 0.000166  loss: 0.2973 (0.3079)  time: 6.0808  data: 1.7378  max mem: 22633
[13:19:03.269385] Epoch: [5]  [ 840/1527]  eta: 1:06:28  lr: 0.000167  loss: 0.2958 (0.3077)  time: 5.3650  data: 1.4580  max mem: 22633
[13:20:54.097603] Epoch: [5]  [ 860/1527]  eta: 1:04:28  lr: 0.000167  loss: 0.2960 (0.3074)  time: 5.5413  data: 1.8015  max mem: 22633
[13:22:53.727699] Epoch: [5]  [ 880/1527]  eta: 1:02:35  lr: 0.000167  loss: 0.2916 (0.3071)  time: 5.9814  data: 1.8428  max mem: 22633
[13:24:50.964187] Epoch: [5]  [ 900/1527]  eta: 1:00:40  lr: 0.000168  loss: 0.2952 (0.3068)  time: 5.8618  data: 1.1103  max mem: 22633
[13:26:40.110008] Epoch: [5]  [ 920/1527]  eta: 0:58:39  lr: 0.000168  loss: 0.2974 (0.3066)  time: 5.4572  data: 1.1385  max mem: 22633
[13:28:28.437587] Epoch: [5]  [ 940/1527]  eta: 0:56:38  lr: 0.000168  loss: 0.2929 (0.3063)  time: 5.4163  data: 1.3837  max mem: 22633
[13:30:17.929196] Epoch: [5]  [ 960/1527]  eta: 0:54:39  lr: 0.000169  loss: 0.2907 (0.3060)  time: 5.4745  data: 1.2259  max mem: 22633
[13:32:08.401518] Epoch: [5]  [ 980/1527]  eta: 0:52:40  lr: 0.000169  loss: 0.2906 (0.3058)  time: 5.5236  data: 1.9672  max mem: 22633
[13:33:58.230173] Epoch: [5]  [1000/1527]  eta: 0:50:41  lr: 0.000170  loss: 0.2922 (0.3055)  time: 5.4914  data: 2.5087  max mem: 22633
[13:36:00.841464] Epoch: [5]  [1020/1527]  eta: 0:48:50  lr: 0.000170  loss: 0.2894 (0.3052)  time: 6.1305  data: 2.0192  max mem: 22633
[13:37:40.920426] Epoch: [5]  [1040/1527]  eta: 0:46:47  lr: 0.000170  loss: 0.2934 (0.3050)  time: 5.0039  data: 2.7350  max mem: 22633
[13:39:29.542741] Epoch: [5]  [1060/1527]  eta: 0:44:49  lr: 0.000171  loss: 0.2903 (0.3048)  time: 5.4308  data: 4.0300  max mem: 22633
[13:41:23.702295] Epoch: [5]  [1080/1527]  eta: 0:42:53  lr: 0.000171  loss: 0.2929 (0.3045)  time: 5.7079  data: 3.3220  max mem: 22633
[13:43:09.788679] Epoch: [5]  [1100/1527]  eta: 0:40:54  lr: 0.000172  loss: 0.2867 (0.3043)  time: 5.3043  data: 4.7083  max mem: 22633
[13:45:01.073914] Epoch: [5]  [1120/1527]  eta: 0:38:58  lr: 0.000172  loss: 0.2878 (0.3040)  time: 5.5642  data: 4.4999  max mem: 22633
[13:47:06.284579] Epoch: [5]  [1140/1527]  eta: 0:37:07  lr: 0.000172  loss: 0.2890 (0.3037)  time: 6.2605  data: 4.5081  max mem: 22633
[13:49:00.619003] Epoch: [5]  [1160/1527]  eta: 0:35:11  lr: 0.000173  loss: 0.2869 (0.3035)  time: 5.7166  data: 3.9017  max mem: 22633
[13:51:03.915005] Epoch: [5]  [1180/1527]  eta: 0:33:19  lr: 0.000173  loss: 0.2900 (0.3033)  time: 6.1647  data: 3.8318  max mem: 22633
[13:53:02.338720] Epoch: [5]  [1200/1527]  eta: 0:31:24  lr: 0.000174  loss: 0.2892 (0.3030)  time: 5.9211  data: 4.6463  max mem: 22633
[13:55:01.674657] Epoch: [5]  [1220/1527]  eta: 0:29:30  lr: 0.000174  loss: 0.2855 (0.3028)  time: 5.9667  data: 4.2577  max mem: 22633
[13:56:58.067509] Epoch: [5]  [1240/1527]  eta: 0:27:35  lr: 0.000174  loss: 0.2862 (0.3025)  time: 5.8196  data: 4.6465  max mem: 22633
[13:58:52.929037] Epoch: [5]  [1260/1527]  eta: 0:25:39  lr: 0.000175  loss: 0.2863 (0.3023)  time: 5.7430  data: 4.1408  max mem: 22633
[14:00:53.668746] Epoch: [5]  [1280/1527]  eta: 0:23:45  lr: 0.000175  loss: 0.2884 (0.3020)  time: 6.0369  data: 3.9175  max mem: 22633
[14:02:40.223065] Epoch: [5]  [1300/1527]  eta: 0:21:48  lr: 0.000176  loss: 0.2851 (0.3018)  time: 5.3274  data: 3.6258  max mem: 22633
[14:04:43.396136] Epoch: [5]  [1320/1527]  eta: 0:19:54  lr: 0.000176  loss: 0.2841 (0.3015)  time: 6.1586  data: 4.9061  max mem: 22633
[14:06:40.831598] Epoch: [5]  [1340/1527]  eta: 0:17:59  lr: 0.000176  loss: 0.2841 (0.3013)  time: 5.8717  data: 3.9090  max mem: 22633
[14:08:30.779242] Epoch: [5]  [1360/1527]  eta: 0:16:03  lr: 0.000177  loss: 0.2831 (0.3010)  time: 5.4973  data: 3.0907  max mem: 22633
[14:10:27.337723] Epoch: [5]  [1380/1527]  eta: 0:14:08  lr: 0.000177  loss: 0.2815 (0.3007)  time: 5.8278  data: 3.1865  max mem: 22633
[14:12:23.793211] Epoch: [5]  [1400/1527]  eta: 0:12:12  lr: 0.000178  loss: 0.2833 (0.3005)  time: 5.8227  data: 2.2773  max mem: 22633
[14:14:13.445162] Epoch: [5]  [1420/1527]  eta: 0:10:16  lr: 0.000178  loss: 0.2800 (0.3002)  time: 5.4825  data: 1.2375  max mem: 22633
[14:16:18.850708] Epoch: [5]  [1440/1527]  eta: 0:08:22  lr: 0.000178  loss: 0.2804 (0.3000)  time: 6.2702  data: 0.9073  max mem: 22633
[14:18:11.295539] Epoch: [5]  [1460/1527]  eta: 0:06:26  lr: 0.000179  loss: 0.2816 (0.2997)  time: 5.6222  data: 0.5539  max mem: 22633
[14:20:05.909734] Epoch: [5]  [1480/1527]  eta: 0:04:31  lr: 0.000179  loss: 0.2782 (0.2995)  time: 5.7306  data: 0.2806  max mem: 22633
[14:22:01.761019] Epoch: [5]  [1500/1527]  eta: 0:02:35  lr: 0.000179  loss: 0.2848 (0.2993)  time: 5.7925  data: 0.0004  max mem: 22633
[14:23:45.766191] Epoch: [5]  [1520/1527]  eta: 0:00:40  lr: 0.000180  loss: 0.2827 (0.2991)  time: 5.2002  data: 0.0024  max mem: 22633
[14:25:15.403359] Epoch: [5]  [1526/1527]  eta: 0:00:05  lr: 0.000180  loss: 0.2793 (0.2990)  time: 7.7140  data: 0.0155  max mem: 22633
[14:25:15.734490] Epoch: [5] Total time: 2:27:35 (5.7994 s / it)
[14:25:15.735699] Averaged stats: lr: 0.000180  loss: 0.2793 (0.2991)
[14:25:17.901179] log_dir: /proj/cloudrobotics-nest/users/Stacking/dataset/CloudGripper_push_1k/pre_trained_weights/vit_base_single_node_s_d
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[14:26:26.586686] torch.Size([256, 3, 224, 224])
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[14:28:05.303387] Epoch: [6]  [   0/1527]  eta: 1 day, 3:00:04  lr: 0.000180  loss: 0.2691 (0.2691)  time: 63.6573  data: 24.5771  max mem: 22633
[14:29:33.443847] Epoch: [6]  [  20/1527]  eta: 3:01:33  lr: 0.000180  loss: 0.2831 (0.2847)  time: 4.4069  data: 0.0037  max mem: 22633
[14:31:32.289212] Epoch: [6]  [  40/1527]  eta: 2:43:35  lr: 0.000181  loss: 0.2794 (0.2829)  time: 5.9422  data: 1.4452  max mem: 22633
[14:33:01.292783] Epoch: [6]  [  60/1527]  eta: 2:24:09  lr: 0.000181  loss: 0.2772 (0.2817)  time: 4.4501  data: 1.3424  max mem: 22633
[14:34:51.757881] Epoch: [6]  [  80/1527]  eta: 2:19:57  lr: 0.000182  loss: 0.2761 (0.2810)  time: 5.5222  data: 1.9078  max mem: 22633
[14:36:53.369650] Epoch: [6]  [ 100/1527]  eta: 2:19:17  lr: 0.000182  loss: 0.2745 (0.2802)  time: 6.0703  data: 2.7870  max mem: 22633
[14:38:55.758279] Epoch: [6]  [ 120/1527]  eta: 2:18:20  lr: 0.000182  loss: 0.2805 (0.2801)  time: 6.1187  data: 2.3909  max mem: 22633
[14:40:48.775356] Epoch: [6]  [ 140/1527]  eta: 2:15:33  lr: 0.000183  loss: 0.2748 (0.2796)  time: 5.6500  data: 1.2128  max mem: 22633
[14:42:39.021854] Epoch: [6]  [ 160/1527]  eta: 2:12:36  lr: 0.000183  loss: 0.2772 (0.2795)  time: 5.5114  data: 1.5899  max mem: 22633
[14:44:39.189648] Epoch: [6]  [ 180/1527]  eta: 2:11:08  lr: 0.000184  loss: 0.2766 (0.2792)  time: 6.0079  data: 0.4355  max mem: 22633
[14:46:45.403165] Epoch: [6]  [ 200/1527]  eta: 2:10:13  lr: 0.000184  loss: 0.2725 (0.2785)  time: 6.3098  data: 0.0012  max mem: 22633
[14:48:29.460982] Epoch: [6]  [ 220/1527]  eta: 2:06:54  lr: 0.000184  loss: 0.2754 (0.2784)  time: 5.2017  data: 0.0005  max mem: 22633
[14:50:21.390079] Epoch: [6]  [ 240/1527]  eta: 2:04:33  lr: 0.000185  loss: 0.2743 (0.2781)  time: 5.5962  data: 0.0004  max mem: 22633
[14:51:57.711231] Epoch: [6]  [ 260/1527]  eta: 2:01:00  lr: 0.000185  loss: 0.2722 (0.2777)  time: 4.8160  data: 0.0003  max mem: 22633
[14:53:45.237905] Epoch: [6]  [ 280/1527]  eta: 1:58:34  lr: 0.000186  loss: 0.2766 (0.2778)  time: 5.3763  data: 0.0004  max mem: 22633
[14:55:39.239095] Epoch: [6]  [ 300/1527]  eta: 1:56:40  lr: 0.000186  loss: 0.2739 (0.2776)  time: 5.7000  data: 0.0005  max mem: 22633
[14:57:29.455135] Epoch: [6]  [ 320/1527]  eta: 1:54:31  lr: 0.000186  loss: 0.2732 (0.2773)  time: 5.5107  data: 0.0004  max mem: 22633
[14:59:26.458822] Epoch: [6]  [ 340/1527]  eta: 1:52:48  lr: 0.000187  loss: 0.2717 (0.2771)  time: 5.8501  data: 0.0004  max mem: 22633
[15:01:14.804629] Epoch: [6]  [ 360/1527]  eta: 1:50:36  lr: 0.000187  loss: 0.2715 (0.2769)  time: 5.4172  data: 0.0005  max mem: 22633
[15:02:58.405683] Epoch: [6]  [ 380/1527]  eta: 1:48:11  lr: 0.000187  loss: 0.2731 (0.2768)  time: 5.1800  data: 0.0003  max mem: 22633
[15:04:48.661317] Epoch: [6]  [ 400/1527]  eta: 1:46:10  lr: 0.000188  loss: 0.2731 (0.2766)  time: 5.5127  data: 0.0004  max mem: 22633
[15:06:48.325862] Epoch: [6]  [ 420/1527]  eta: 1:44:34  lr: 0.000188  loss: 0.2712 (0.2764)  time: 5.9829  data: 0.0004  max mem: 22633
[15:08:37.718978] Epoch: [6]  [ 440/1527]  eta: 1:42:31  lr: 0.000189  loss: 0.2686 (0.2761)  time: 5.4696  data: 0.0003  max mem: 22633
[15:10:25.318799] Epoch: [6]  [ 460/1527]  eta: 1:40:25  lr: 0.000189  loss: 0.2717 (0.2760)  time: 5.3799  data: 0.0004  max mem: 22633
[15:12:23.659033] Epoch: [6]  [ 480/1527]  eta: 1:38:44  lr: 0.000189  loss: 0.2675 (0.2757)  time: 5.9169  data: 0.0003  max mem: 22633
[15:14:11.207013] Epoch: [6]  [ 500/1527]  eta: 1:36:39  lr: 0.000190  loss: 0.2677 (0.2755)  time: 5.3773  data: 0.0004  max mem: 22633
[15:16:03.220811] Epoch: [6]  [ 520/1527]  eta: 1:34:44  lr: 0.000190  loss: 0.2675 (0.2753)  time: 5.6006  data: 0.0004  max mem: 22633
[15:17:53.526854] Epoch: [6]  [ 540/1527]  eta: 1:32:47  lr: 0.000191  loss: 0.2695 (0.2751)  time: 5.5152  data: 0.0004  max mem: 22633
[15:19:46.006016] Epoch: [6]  [ 560/1527]  eta: 1:30:53  lr: 0.000191  loss: 0.2675 (0.2749)  time: 5.6239  data: 0.0004  max mem: 22633
[15:21:38.335758] Epoch: [6]  [ 580/1527]  eta: 1:29:00  lr: 0.000191  loss: 0.2653 (0.2746)  time: 5.6164  data: 0.0004  max mem: 22633
[15:23:24.561855] Epoch: [6]  [ 600/1527]  eta: 1:26:57  lr: 0.000192  loss: 0.2639 (0.2743)  time: 5.3112  data: 0.0004  max mem: 22633
[15:25:18.337836] Epoch: [6]  [ 620/1527]  eta: 1:25:06  lr: 0.000192  loss: 0.2677 (0.2742)  time: 5.6887  data: 0.0004  max mem: 22633
[15:27:06.077154] Epoch: [6]  [ 640/1527]  eta: 1:23:07  lr: 0.000193  loss: 0.2658 (0.2740)  time: 5.3869  data: 0.0004  max mem: 22633
[15:28:59.949873] Epoch: [6]  [ 660/1527]  eta: 1:21:16  lr: 0.000193  loss: 0.2648 (0.2737)  time: 5.6936  data: 0.0005  max mem: 22633
[15:30:41.676309] Epoch: [6]  [ 680/1527]  eta: 1:19:10  lr: 0.000193  loss: 0.2678 (0.2735)  time: 5.0863  data: 0.0032  max mem: 22633
[15:32:31.779654] Epoch: [6]  [ 700/1527]  eta: 1:17:16  lr: 0.000194  loss: 0.2662 (0.2733)  time: 5.5051  data: 0.0004  max mem: 22633
[15:34:27.159610] Epoch: [6]  [ 720/1527]  eta: 1:15:27  lr: 0.000194  loss: 0.2635 (0.2731)  time: 5.7689  data: 0.0005  max mem: 22633
[15:36:17.230654] Epoch: [6]  [ 740/1527]  eta: 1:13:33  lr: 0.000195  loss: 0.2636 (0.2729)  time: 5.5035  data: 0.0004  max mem: 22633
[15:38:00.567582] Epoch: [6]  [ 760/1527]  eta: 1:11:32  lr: 0.000195  loss: 0.2635 (0.2727)  time: 5.1668  data: 0.0003  max mem: 22633
[15:39:48.323500] Epoch: [6]  [ 780/1527]  eta: 1:09:36  lr: 0.000195  loss: 0.2661 (0.2725)  time: 5.3877  data: 0.0177  max mem: 22633
[15:41:29.522175] Epoch: [6]  [ 800/1527]  eta: 1:07:34  lr: 0.000196  loss: 0.2634 (0.2723)  time: 5.0599  data: 0.0524  max mem: 22633
[15:43:28.018302] Epoch: [6]  [ 820/1527]  eta: 1:05:49  lr: 0.000196  loss: 0.2613 (0.2720)  time: 5.9247  data: 0.0505  max mem: 22633
[15:45:11.327424] Epoch: [6]  [ 840/1527]  eta: 1:03:50  lr: 0.000197  loss: 0.2618 (0.2718)  time: 5.1654  data: 0.0358  max mem: 22633
[15:47:00.296347] Epoch: [6]  [ 860/1527]  eta: 1:01:57  lr: 0.000197  loss: 0.2599 (0.2716)  time: 5.4484  data: 0.3586  max mem: 22633
[15:48:55.034002] Epoch: [6]  [ 880/1527]  eta: 1:00:08  lr: 0.000197  loss: 0.2619 (0.2714)  time: 5.7368  data: 0.0306  max mem: 22633
[15:50:35.712600] Epoch: [6]  [ 900/1527]  eta: 0:58:08  lr: 0.000198  loss: 0.2605 (0.2712)  time: 5.0339  data: 0.0217  max mem: 22633
[15:52:23.686598] Epoch: [6]  [ 920/1527]  eta: 0:56:15  lr: 0.000198  loss: 0.2591 (0.2709)  time: 5.3986  data: 0.0487  max mem: 22633
[15:54:13.482317] Epoch: [6]  [ 940/1527]  eta: 0:54:23  lr: 0.000198  loss: 0.2595 (0.2707)  time: 5.4896  data: 0.5082  max mem: 22633
[15:56:18.601641] Epoch: [6]  [ 960/1527]  eta: 0:52:40  lr: 0.000199  loss: 0.2590 (0.2705)  time: 6.2559  data: 0.6343  max mem: 22633
[15:58:01.735200] Epoch: [6]  [ 980/1527]  eta: 0:50:44  lr: 0.000199  loss: 0.2589 (0.2703)  time: 5.1564  data: 0.8883  max mem: 22633
[15:59:45.640787] Epoch: [6]  [1000/1527]  eta: 0:48:49  lr: 0.000200  loss: 0.2586 (0.2701)  time: 5.1952  data: 0.8274  max mem: 22633
[16:01:31.994359] Epoch: [6]  [1020/1527]  eta: 0:46:55  lr: 0.000200  loss: 0.2586 (0.2699)  time: 5.3176  data: 0.0703  max mem: 22633
[16:03:24.642186] Epoch: [6]  [1040/1527]  eta: 0:45:05  lr: 0.000200  loss: 0.2584 (0.2697)  time: 5.6323  data: 0.0567  max mem: 22633
[16:05:24.783211] Epoch: [6]  [1060/1527]  eta: 0:43:18  lr: 0.000201  loss: 0.2569 (0.2695)  time: 6.0070  data: 0.0369  max mem: 22633
[16:07:22.761205] Epoch: [6]  [1080/1527]  eta: 0:41:29  lr: 0.000201  loss: 0.2565 (0.2693)  time: 5.8988  data: 0.0004  max mem: 22633
[16:09:06.972914] Epoch: [6]  [1100/1527]  eta: 0:39:35  lr: 0.000202  loss: 0.2575 (0.2691)  time: 5.2105  data: 0.0163  max mem: 22633
[16:10:55.142292] Epoch: [6]  [1120/1527]  eta: 0:37:43  lr: 0.000202  loss: 0.2571 (0.2689)  time: 5.4084  data: 0.0429  max mem: 22633
[16:12:48.096036] Epoch: [6]  [1140/1527]  eta: 0:35:52  lr: 0.000202  loss: 0.2547 (0.2687)  time: 5.6476  data: 0.0266  max mem: 22633
[16:14:41.106824] Epoch: [6]  [1160/1527]  eta: 0:34:01  lr: 0.000203  loss: 0.2554 (0.2685)  time: 5.6504  data: 0.0004  max mem: 22633
[16:16:19.787495] Epoch: [6]  [1180/1527]  eta: 0:32:06  lr: 0.000203  loss: 0.2559 (0.2683)  time: 4.9340  data: 0.0157  max mem: 22633
[16:18:20.608315] Epoch: [6]  [1200/1527]  eta: 0:30:18  lr: 0.000204  loss: 0.2556 (0.2681)  time: 6.0409  data: 0.0216  max mem: 22633
[16:20:09.683644] Epoch: [6]  [1220/1527]  eta: 0:28:26  lr: 0.000204  loss: 0.2562 (0.2679)  time: 5.4536  data: 0.0045  max mem: 22633
[16:22:03.524298] Epoch: [6]  [1240/1527]  eta: 0:26:36  lr: 0.000204  loss: 0.2553 (0.2677)  time: 5.6919  data: 0.0190  max mem: 22633
[16:23:54.856103] Epoch: [6]  [1260/1527]  eta: 0:24:44  lr: 0.000205  loss: 0.2544 (0.2675)  time: 5.5665  data: 0.5332  max mem: 22633
[16:25:42.168566] Epoch: [6]  [1280/1527]  eta: 0:22:52  lr: 0.000205  loss: 0.2543 (0.2673)  time: 5.3655  data: 0.3535  max mem: 22633
[16:27:20.297732] Epoch: [6]  [1300/1527]  eta: 0:20:59  lr: 0.000206  loss: 0.2567 (0.2672)  time: 4.9064  data: 0.0126  max mem: 22633
[16:29:08.110524] Epoch: [6]  [1320/1527]  eta: 0:19:07  lr: 0.000206  loss: 0.2529 (0.2670)  time: 5.3904  data: 0.0762  max mem: 22633
[16:30:49.402502] Epoch: [6]  [1340/1527]  eta: 0:17:15  lr: 0.000206  loss: 0.2515 (0.2667)  time: 5.0645  data: 0.2439  max mem: 22633
[16:32:41.004458] Epoch: [6]  [1360/1527]  eta: 0:15:25  lr: 0.000207  loss: 0.2557 (0.2666)  time: 5.5800  data: 0.0004  max mem: 22633
[16:34:33.598076] Epoch: [6]  [1380/1527]  eta: 0:13:34  lr: 0.000207  loss: 0.2518 (0.2664)  time: 5.6296  data: 0.0004  max mem: 22633
[16:36:21.310826] Epoch: [6]  [1400/1527]  eta: 0:11:43  lr: 0.000208  loss: 0.2530 (0.2662)  time: 5.3856  data: 0.0085  max mem: 22633
[16:38:24.006952] Epoch: [6]  [1420/1527]  eta: 0:09:53  lr: 0.000208  loss: 0.2518 (0.2660)  time: 6.1347  data: 0.0004  max mem: 22633
[16:40:22.065582] Epoch: [6]  [1440/1527]  eta: 0:08:02  lr: 0.000208  loss: 0.2483 (0.2658)  time: 5.9028  data: 0.0005  max mem: 22633
[16:42:13.264715] Epoch: [6]  [1460/1527]  eta: 0:06:11  lr: 0.000209  loss: 0.2491 (0.2656)  time: 5.5599  data: 0.0004  max mem: 22633
[16:43:56.570249] Epoch: [6]  [1480/1527]  eta: 0:04:20  lr: 0.000209  loss: 0.2496 (0.2654)  time: 5.1652  data: 0.0004  max mem: 22633
[16:45:44.445684] Epoch: [6]  [1500/1527]  eta: 0:02:29  lr: 0.000209  loss: 0.2493 (0.2652)  time: 5.3937  data: 0.0005  max mem: 22633
[16:48:06.821563] Epoch: [6]  [1520/1527]  eta: 0:00:38  lr: 0.000210  loss: 0.2478 (0.2650)  time: 7.1183  data: 0.0025  max mem: 22633
[16:49:13.128647] Epoch: [6]  [1526/1527]  eta: 0:00:05  lr: 0.000210  loss: 0.2478 (0.2649)  time: 9.2823  data: 0.0023  max mem: 22633
[16:49:13.366382] Epoch: [6] Total time: 2:22:11 (5.5872 s / it)
[16:49:13.405814] Averaged stats: lr: 0.000210  loss: 0.2478 (0.2650)
[16:49:13.410922] log_dir: /proj/cloudrobotics-nest/users/Stacking/dataset/CloudGripper_push_1k/pre_trained_weights/vit_base_single_node_s_d
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[16:50:08.451231] torch.Size([256, 3, 224, 224])
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[16:51:20.487300] Epoch: [7]  [   0/1527]  eta: 19:25:59  lr: 0.000210  loss: 0.2475 (0.2475)  time: 45.8152  data: 31.1414  max mem: 22633
[16:52:48.716252] Epoch: [7]  [  20/1527]  eta: 2:40:19  lr: 0.000210  loss: 0.2460 (0.2483)  time: 4.4114  data: 2.0396  max mem: 22633
[16:54:35.312807] Epoch: [7]  [  40/1527]  eta: 2:25:27  lr: 0.000211  loss: 0.2486 (0.2488)  time: 5.3297  data: 2.0880  max mem: 22633
[16:56:24.659045] Epoch: [7]  [  60/1527]  eta: 2:20:16  lr: 0.000211  loss: 0.2480 (0.2492)  time: 5.4672  data: 0.4012  max mem: 22633
[16:58:18.307098] Epoch: [7]  [  80/1527]  eta: 2:18:02  lr: 0.000212  loss: 0.2470 (0.2495)  time: 5.6823  data: 0.0923  max mem: 22633
[17:00:17.180187] Epoch: [7]  [ 100/1527]  eta: 2:17:09  lr: 0.000212  loss: 0.2470 (0.2494)  time: 5.9436  data: 0.0424  max mem: 22633
[17:02:01.995717] Epoch: [7]  [ 120/1527]  eta: 2:13:12  lr: 0.000212  loss: 0.2440 (0.2488)  time: 5.2407  data: 0.0335  max mem: 22633
[17:03:58.415260] Epoch: [7]  [ 140/1527]  eta: 2:11:46  lr: 0.000213  loss: 0.2466 (0.2487)  time: 5.8209  data: 0.0336  max mem: 22633
[17:05:44.135657] Epoch: [7]  [ 160/1527]  eta: 2:08:41  lr: 0.000213  loss: 0.2465 (0.2485)  time: 5.2859  data: 0.1479  max mem: 22633
[17:07:37.358605] Epoch: [7]  [ 180/1527]  eta: 2:06:50  lr: 0.000214  loss: 0.2477 (0.2485)  time: 5.6611  data: 0.0078  max mem: 22633
[17:09:36.124229] Epoch: [7]  [ 200/1527]  eta: 2:05:35  lr: 0.000214  loss: 0.2446 (0.2482)  time: 5.9382  data: 0.0040  max mem: 22633
[17:11:16.256075] Epoch: [7]  [ 220/1527]  eta: 2:02:22  lr: 0.000214  loss: 0.2460 (0.2481)  time: 5.0065  data: 0.0004  max mem: 22633
[17:13:02.847076] Epoch: [7]  [ 240/1527]  eta: 1:59:59  lr: 0.000215  loss: 0.2435 (0.2479)  time: 5.3291  data: 0.0559  max mem: 22633
[17:14:59.752831] Epoch: [7]  [ 260/1527]  eta: 1:58:31  lr: 0.000215  loss: 0.2449 (0.2477)  time: 5.8452  data: 0.1186  max mem: 22633
[17:16:45.344625] Epoch: [7]  [ 280/1527]  eta: 1:56:10  lr: 0.000216  loss: 0.2449 (0.2476)  time: 5.2795  data: 0.4562  max mem: 22633
[17:18:36.019496] Epoch: [7]  [ 300/1527]  eta: 1:54:13  lr: 0.000216  loss: 0.2423 (0.2473)  time: 5.5337  data: 0.5825  max mem: 22633
[17:20:27.913318] Epoch: [7]  [ 320/1527]  eta: 1:52:22  lr: 0.000216  loss: 0.2450 (0.2473)  time: 5.5944  data: 0.2001  max mem: 22633
[17:22:22.136075] Epoch: [7]  [ 340/1527]  eta: 1:50:39  lr: 0.000217  loss: 0.2428 (0.2471)  time: 5.7111  data: 0.0004  max mem: 22633
[17:24:16.249905] Epoch: [7]  [ 360/1527]  eta: 1:48:54  lr: 0.000217  loss: 0.2428 (0.2470)  time: 5.7056  data: 0.0004  max mem: 22633
[17:26:06.271022] Epoch: [7]  [ 380/1527]  eta: 1:46:57  lr: 0.000217  loss: 0.2421 (0.2467)  time: 5.5010  data: 0.0005  max mem: 22633
[17:28:02.882331] Epoch: [7]  [ 400/1527]  eta: 1:45:18  lr: 0.000218  loss: 0.2420 (0.2465)  time: 5.8303  data: 0.0004  max mem: 22633
[17:29:41.974370] Epoch: [7]  [ 420/1527]  eta: 1:42:51  lr: 0.000218  loss: 0.2426 (0.2464)  time: 4.9545  data: 0.0005  max mem: 22633
[17:31:34.494543] Epoch: [7]  [ 440/1527]  eta: 1:41:02  lr: 0.000219  loss: 0.2401 (0.2461)  time: 5.6259  data: 0.0004  max mem: 22633
[17:33:28.691174] Epoch: [7]  [ 460/1527]  eta: 1:39:17  lr: 0.000219  loss: 0.2427 (0.2461)  time: 5.7094  data: 0.0217  max mem: 22633
[17:35:27.259879] Epoch: [7]  [ 480/1527]  eta: 1:37:40  lr: 0.000219  loss: 0.2413 (0.2460)  time: 5.9284  data: 0.0342  max mem: 22633
[17:37:18.383578] Epoch: [7]  [ 500/1527]  eta: 1:35:47  lr: 0.000220  loss: 0.2421 (0.2458)  time: 5.5559  data: 0.0218  max mem: 22633
[17:39:17.722725] Epoch: [7]  [ 520/1527]  eta: 1:34:09  lr: 0.000220  loss: 0.2405 (0.2456)  time: 5.9669  data: 0.0042  max mem: 22633
[17:41:10.307917] Epoch: [7]  [ 540/1527]  eta: 1:32:18  lr: 0.000221  loss: 0.2367 (0.2453)  time: 5.6288  data: 0.0004  max mem: 22633
[17:42:55.930638] Epoch: [7]  [ 560/1527]  eta: 1:30:14  lr: 0.000221  loss: 0.2407 (0.2452)  time: 5.2811  data: 0.0003  max mem: 22633
[17:44:46.507591] Epoch: [7]  [ 580/1527]  eta: 1:28:20  lr: 0.000221  loss: 0.2386 (0.2451)  time: 5.5288  data: 0.0004  max mem: 22633
[17:46:26.910586] Epoch: [7]  [ 600/1527]  eta: 1:26:10  lr: 0.000222  loss: 0.2361 (0.2449)  time: 5.0201  data: 0.0091  max mem: 22633
[17:48:19.929058] Epoch: [7]  [ 620/1527]  eta: 1:24:21  lr: 0.000222  loss: 0.2413 (0.2448)  time: 5.6508  data: 0.0004  max mem: 22633
[17:50:03.090352] Epoch: [7]  [ 640/1527]  eta: 1:22:17  lr: 0.000223  loss: 0.2366 (0.2446)  time: 5.1380  data: 0.0083  max mem: 22633
[17:51:37.903744] Epoch: [7]  [ 660/1527]  eta: 1:20:04  lr: 0.000223  loss: 0.2353 (0.2444)  time: 4.7406  data: 0.0004  max mem: 22633
[17:53:22.335079] Epoch: [7]  [ 680/1527]  eta: 1:18:05  lr: 0.000223  loss: 0.2374 (0.2442)  time: 5.2215  data: 0.0004  max mem: 22633
[17:55:17.066057] Epoch: [7]  [ 700/1527]  eta: 1:16:19  lr: 0.000224  loss: 0.2380 (0.2441)  time: 5.7365  data: 0.0095  max mem: 22633
[17:57:05.429041] Epoch: [7]  [ 720/1527]  eta: 1:14:26  lr: 0.000224  loss: 0.2365 (0.2439)  time: 5.4181  data: 0.0004  max mem: 22633
[17:58:57.956450] Epoch: [7]  [ 740/1527]  eta: 1:12:37  lr: 0.000225  loss: 0.2373 (0.2437)  time: 5.6259  data: 0.0003  max mem: 22633
[18:00:47.349103] Epoch: [7]  [ 760/1527]  eta: 1:10:45  lr: 0.000225  loss: 0.2353 (0.2436)  time: 5.4696  data: 0.0042  max mem: 22633
[18:02:32.824888] Epoch: [7]  [ 780/1527]  eta: 1:08:49  lr: 0.000225  loss: 0.2357 (0.2434)  time: 5.2737  data: 0.0003  max mem: 22633
[18:04:16.270874] Epoch: [7]  [ 800/1527]  eta: 1:06:52  lr: 0.000226  loss: 0.2372 (0.2432)  time: 5.1722  data: 0.0041  max mem: 22633
[18:06:14.320458] Epoch: [7]  [ 820/1527]  eta: 1:05:08  lr: 0.000226  loss: 0.2338 (0.2430)  time: 5.9024  data: 0.0004  max mem: 22633
[18:08:08.380509] Epoch: [7]  [ 840/1527]  eta: 1:03:21  lr: 0.000227  loss: 0.2336 (0.2428)  time: 5.7029  data: 0.0004  max mem: 22633
[18:10:02.207186] Epoch: [7]  [ 860/1527]  eta: 1:01:32  lr: 0.000227  loss: 0.2362 (0.2427)  time: 5.6912  data: 0.0089  max mem: 22633
[18:12:04.363891] Epoch: [7]  [ 880/1527]  eta: 0:59:50  lr: 0.000227  loss: 0.2320 (0.2424)  time: 6.1078  data: 0.0004  max mem: 22633
[18:14:03.166549] Epoch: [7]  [ 900/1527]  eta: 0:58:05  lr: 0.000228  loss: 0.2332 (0.2423)  time: 5.9400  data: 0.0003  max mem: 22633
[18:15:48.365519] Epoch: [7]  [ 920/1527]  eta: 0:56:09  lr: 0.000228  loss: 0.2342 (0.2421)  time: 5.2599  data: 0.0003  max mem: 22633
[18:17:46.580642] Epoch: [7]  [ 940/1527]  eta: 0:54:23  lr: 0.000228  loss: 0.2352 (0.2419)  time: 5.9107  data: 0.0003  max mem: 22633
[18:19:39.929548] Epoch: [7]  [ 960/1527]  eta: 0:52:33  lr: 0.000229  loss: 0.2351 (0.2418)  time: 5.6673  data: 0.0003  max mem: 22633
[18:21:42.298822] Epoch: [7]  [ 980/1527]  eta: 0:50:48  lr: 0.000229  loss: 0.2307 (0.2416)  time: 6.1184  data: 0.0004  max mem: 22633
[18:23:24.645319] Epoch: [7]  [1000/1527]  eta: 0:48:52  lr: 0.000230  loss: 0.2320 (0.2415)  time: 5.1172  data: 0.0004  max mem: 22633
[18:25:12.365282] Epoch: [7]  [1020/1527]  eta: 0:46:59  lr: 0.000230  loss: 0.2331 (0.2413)  time: 5.3859  data: 0.0003  max mem: 22633
[18:27:07.258654] Epoch: [7]  [1040/1527]  eta: 0:45:09  lr: 0.000230  loss: 0.2313 (0.2411)  time: 5.7446  data: 0.0004  max mem: 22633
[18:28:43.946137] Epoch: [7]  [1060/1527]  eta: 0:43:11  lr: 0.000231  loss: 0.2325 (0.2410)  time: 4.8343  data: 0.0003  max mem: 22633
[18:30:38.016143] Epoch: [7]  [1080/1527]  eta: 0:41:22  lr: 0.000231  loss: 0.2270 (0.2407)  time: 5.7033  data: 0.0005  max mem: 22633
[18:32:30.437597] Epoch: [7]  [1100/1527]  eta: 0:39:31  lr: 0.000232  loss: 0.2304 (0.2405)  time: 5.6210  data: 0.0004  max mem: 22633
[18:34:23.371451] Epoch: [7]  [1120/1527]  eta: 0:37:41  lr: 0.000232  loss: 0.2294 (0.2403)  time: 5.6466  data: 0.0004  max mem: 22633
[18:36:17.543678] Epoch: [7]  [1140/1527]  eta: 0:35:51  lr: 0.000232  loss: 0.2282 (0.2401)  time: 5.7085  data: 0.0004  max mem: 22633
[18:38:11.021843] Epoch: [7]  [1160/1527]  eta: 0:34:00  lr: 0.000233  loss: 0.2292 (0.2400)  time: 5.6738  data: 0.0004  max mem: 22633
[18:40:08.735238] Epoch: [7]  [1180/1527]  eta: 0:32:11  lr: 0.000233  loss: 0.2288 (0.2398)  time: 5.8856  data: 0.0044  max mem: 22633
[18:41:58.067650] Epoch: [7]  [1200/1527]  eta: 0:30:19  lr: 0.000234  loss: 0.2286 (0.2396)  time: 5.4665  data: 0.0004  max mem: 22633
[18:43:54.617014] Epoch: [7]  [1220/1527]  eta: 0:28:29  lr: 0.000234  loss: 0.2258 (0.2395)  time: 5.8271  data: 0.0125  max mem: 22633
[18:45:50.382021] Epoch: [7]  [1240/1527]  eta: 0:26:39  lr: 0.000234  loss: 0.2278 (0.2393)  time: 5.7882  data: 0.0254  max mem: 22633
[18:47:39.353449] Epoch: [7]  [1260/1527]  eta: 0:24:47  lr: 0.000235  loss: 0.2308 (0.2392)  time: 5.4485  data: 0.0087  max mem: 22633
[18:49:32.090121] Epoch: [7]  [1280/1527]  eta: 0:22:56  lr: 0.000235  loss: 0.2263 (0.2390)  time: 5.6368  data: 0.0004  max mem: 22633
[18:51:25.011012] Epoch: [7]  [1300/1527]  eta: 0:21:04  lr: 0.000236  loss: 0.2273 (0.2388)  time: 5.6460  data: 0.0004  max mem: 22633
[18:53:19.856302] Epoch: [7]  [1320/1527]  eta: 0:19:14  lr: 0.000236  loss: 0.2269 (0.2386)  time: 5.7422  data: 0.0254  max mem: 22633
[18:55:07.930207] Epoch: [7]  [1340/1527]  eta: 0:17:22  lr: 0.000236  loss: 0.2261 (0.2385)  time: 5.4036  data: 0.0293  max mem: 22633
[18:56:59.483898] Epoch: [7]  [1360/1527]  eta: 0:15:30  lr: 0.000237  loss: 0.2274 (0.2383)  time: 5.5776  data: 0.0644  max mem: 22633
[18:58:50.950851] Epoch: [7]  [1380/1527]  eta: 0:13:39  lr: 0.000237  loss: 0.2263 (0.2381)  time: 5.5733  data: 0.0533  max mem: 22633
[19:00:35.256501] Epoch: [7]  [1400/1527]  eta: 0:11:47  lr: 0.000238  loss: 0.2278 (0.2380)  time: 5.2149  data: 0.0390  max mem: 22633
[19:02:34.861776] Epoch: [7]  [1420/1527]  eta: 0:09:56  lr: 0.000238  loss: 0.2222 (0.2378)  time: 5.9802  data: 0.0251  max mem: 22633
[19:04:06.540190] Epoch: [7]  [1440/1527]  eta: 0:08:03  lr: 0.000238  loss: 0.2234 (0.2376)  time: 4.5838  data: 0.0345  max mem: 22633
[19:05:51.475887] Epoch: [7]  [1460/1527]  eta: 0:06:12  lr: 0.000239  loss: 0.2222 (0.2375)  time: 5.2467  data: 0.8690  max mem: 22633
[19:07:46.902847] Epoch: [7]  [1480/1527]  eta: 0:04:21  lr: 0.000239  loss: 0.2268 (0.2373)  time: 5.7713  data: 1.3630  max mem: 22633
[19:09:33.330135] Epoch: [7]  [1500/1527]  eta: 0:02:29  lr: 0.000239  loss: 0.2233 (0.2372)  time: 5.3213  data: 1.5104  max mem: 22633
[19:11:54.966112] Epoch: [7]  [1520/1527]  eta: 0:00:39  lr: 0.000240  loss: 0.2211 (0.2370)  time: 7.0817  data: 1.7967  max mem: 22633
[19:13:23.211406] Epoch: [7]  [1526/1527]  eta: 0:00:05  lr: 0.000240  loss: 0.2247 (0.2369)  time: 9.2749  data: 3.3212  max mem: 22633
[19:13:23.481995] Epoch: [7] Total time: 2:22:48 (5.6115 s / it)
[19:13:23.488939] Averaged stats: lr: 0.000240  loss: 0.2247 (0.2370)
[19:13:23.494425] log_dir: /proj/cloudrobotics-nest/users/Stacking/dataset/CloudGripper_push_1k/pre_trained_weights/vit_base_single_node_s_d
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[19:14:35.349356] torch.Size([256, 3, 224, 224])
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[19:15:53.152758] Epoch: [8]  [   0/1527]  eta: 11:45:37  lr: 0.000240  loss: 0.2195 (0.2195)  time: 27.7261  data: 27.4164  max mem: 22633
[19:17:19.334993] Epoch: [8]  [  20/1527]  eta: 2:16:14  lr: 0.000240  loss: 0.2233 (0.2233)  time: 4.3090  data: 3.2322  max mem: 22633
[19:19:09.624604] Epoch: [8]  [  40/1527]  eta: 2:15:31  lr: 0.000241  loss: 0.2221 (0.2227)  time: 5.5144  data: 4.4548  max mem: 22633
[19:20:53.752137] Epoch: [8]  [  60/1527]  eta: 2:11:35  lr: 0.000241  loss: 0.2232 (0.2229)  time: 5.2063  data: 3.6409  max mem: 22633
[19:22:51.300200] Epoch: [8]  [  80/1527]  eta: 2:12:45  lr: 0.000242  loss: 0.2207 (0.2227)  time: 5.8773  data: 4.0816  max mem: 22633
[19:24:40.917925] Epoch: [8]  [ 100/1527]  eta: 2:10:48  lr: 0.000242  loss: 0.2228 (0.2230)  time: 5.4808  data: 3.3129  max mem: 22633
[19:26:24.271563] Epoch: [8]  [ 120/1527]  eta: 2:07:41  lr: 0.000242  loss: 0.2195 (0.2227)  time: 5.1676  data: 2.7314  max mem: 22633
[19:28:05.677900] Epoch: [8]  [ 140/1527]  eta: 2:04:38  lr: 0.000243  loss: 0.2191 (0.2224)  time: 5.0702  data: 1.4237  max mem: 22633
[19:30:02.241604] Epoch: [8]  [ 160/1527]  eta: 2:04:04  lr: 0.000243  loss: 0.2186 (0.2220)  time: 5.8278  data: 1.9177  max mem: 22633
[19:31:46.214030] Epoch: [8]  [ 180/1527]  eta: 2:01:38  lr: 0.000244  loss: 0.2212 (0.2221)  time: 5.1985  data: 0.4665  max mem: 22633
[19:33:39.030840] Epoch: [8]  [ 200/1527]  eta: 2:00:19  lr: 0.000244  loss: 0.2200 (0.2220)  time: 5.6408  data: 1.5902  max mem: 22633
[19:35:24.996687] Epoch: [8]  [ 220/1527]  eta: 1:58:14  lr: 0.000244  loss: 0.2213 (0.2219)  time: 5.2982  data: 1.6395  max mem: 22633
[19:37:12.988751] Epoch: [8]  [ 240/1527]  eta: 1:56:22  lr: 0.000245  loss: 0.2204 (0.2218)  time: 5.3995  data: 2.8422  max mem: 22633
[19:38:55.664874] Epoch: [8]  [ 260/1527]  eta: 1:54:05  lr: 0.000245  loss: 0.2196 (0.2216)  time: 5.1337  data: 2.3171  max mem: 22633
[19:40:43.213612] Epoch: [8]  [ 280/1527]  eta: 1:52:15  lr: 0.000246  loss: 0.2180 (0.2214)  time: 5.3774  data: 2.1057  max mem: 22633
[19:42:32.232968] Epoch: [8]  [ 300/1527]  eta: 1:50:31  lr: 0.000246  loss: 0.2181 (0.2213)  time: 5.4509  data: 2.3917  max mem: 22633
[19:44:14.082053] Epoch: [8]  [ 320/1527]  eta: 1:48:19  lr: 0.000246  loss: 0.2196 (0.2213)  time: 5.0924  data: 2.0483  max mem: 22633
[19:46:05.518340] Epoch: [8]  [ 340/1527]  eta: 1:46:45  lr: 0.000247  loss: 0.2170 (0.2211)  time: 5.5717  data: 3.1358  max mem: 22633
[19:48:01.286649] Epoch: [8]  [ 360/1527]  eta: 1:45:20  lr: 0.000247  loss: 0.2181 (0.2210)  time: 5.7616  data: 3.6676  max mem: 22633
[19:49:53.513355] Epoch: [8]  [ 380/1527]  eta: 1:43:44  lr: 0.000247  loss: 0.2172 (0.2208)  time: 5.6113  data: 2.9887  max mem: 22633
[19:51:54.361193] Epoch: [8]  [ 400/1527]  eta: 1:42:30  lr: 0.000248  loss: 0.2173 (0.2207)  time: 6.0423  data: 1.2150  max mem: 22633
[19:53:32.422646] Epoch: [8]  [ 420/1527]  eta: 1:40:11  lr: 0.000248  loss: 0.2160 (0.2205)  time: 4.8992  data: 1.2321  max mem: 22633
[19:55:11.653052] Epoch: [8]  [ 440/1527]  eta: 1:38:00  lr: 0.000249  loss: 0.2152 (0.2204)  time: 4.9615  data: 1.9167  max mem: 22633
[19:56:57.905646] Epoch: [8]  [ 460/1527]  eta: 1:36:07  lr: 0.000249  loss: 0.2149 (0.2201)  time: 5.3125  data: 1.9348  max mem: 22633
[19:58:52.241517] Epoch: [8]  [ 480/1527]  eta: 1:34:32  lr: 0.000249  loss: 0.2206 (0.2202)  time: 5.7163  data: 1.3645  max mem: 22633
[20:00:38.928087] Epoch: [8]  [ 500/1527]  eta: 1:32:41  lr: 0.000250  loss: 0.2134 (0.2200)  time: 5.3343  data: 2.0871  max mem: 22633
[20:02:33.775267] Epoch: [8]  [ 520/1527]  eta: 1:31:05  lr: 0.000250  loss: 0.2183 (0.2199)  time: 5.7423  data: 3.4628  max mem: 22633
[20:04:31.318422] Epoch: [8]  [ 540/1527]  eta: 1:29:33  lr: 0.000251  loss: 0.2162 (0.2198)  time: 5.8771  data: 4.5032  max mem: 22633
[20:06:32.224078] Epoch: [8]  [ 560/1527]  eta: 1:28:05  lr: 0.000251  loss: 0.2173 (0.2197)  time: 6.0452  data: 3.4705  max mem: 22633
[20:08:38.199295] Epoch: [8]  [ 580/1527]  eta: 1:26:42  lr: 0.000251  loss: 0.2138 (0.2195)  time: 6.2987  data: 1.9598  max mem: 22633
[20:10:24.788336] Epoch: [8]  [ 600/1527]  eta: 1:24:47  lr: 0.000252  loss: 0.2179 (0.2195)  time: 5.3294  data: 0.2624  max mem: 22633
[20:12:07.440855] Epoch: [8]  [ 620/1527]  eta: 1:22:47  lr: 0.000252  loss: 0.2136 (0.2193)  time: 5.1325  data: 0.0394  max mem: 22633
[20:14:03.119906] Epoch: [8]  [ 640/1527]  eta: 1:21:06  lr: 0.000253  loss: 0.2152 (0.2192)  time: 5.7839  data: 0.0329  max mem: 22633
[20:15:56.214130] Epoch: [8]  [ 660/1527]  eta: 1:19:21  lr: 0.000253  loss: 0.2125 (0.2191)  time: 5.6546  data: 0.0168  max mem: 22633
[20:17:37.337621] Epoch: [8]  [ 680/1527]  eta: 1:17:20  lr: 0.000253  loss: 0.2116 (0.2190)  time: 5.0560  data: 0.0082  max mem: 22633
[20:19:35.251279] Epoch: [8]  [ 700/1527]  eta: 1:15:41  lr: 0.000254  loss: 0.2129 (0.2188)  time: 5.8956  data: 0.0491  max mem: 22633
[20:21:18.651589] Epoch: [8]  [ 720/1527]  eta: 1:13:43  lr: 0.000254  loss: 0.2120 (0.2186)  time: 5.1699  data: 0.0333  max mem: 22633
[20:23:06.905400] Epoch: [8]  [ 740/1527]  eta: 1:11:52  lr: 0.000255  loss: 0.2134 (0.2185)  time: 5.4126  data: 0.0474  max mem: 22633
[20:24:54.294689] Epoch: [8]  [ 760/1527]  eta: 1:10:01  lr: 0.000255  loss: 0.2107 (0.2184)  time: 5.3694  data: 0.0435  max mem: 22633
[20:26:40.553489] Epoch: [8]  [ 780/1527]  eta: 1:08:08  lr: 0.000255  loss: 0.2138 (0.2182)  time: 5.3125  data: 0.0200  max mem: 22633
[20:28:33.052532] Epoch: [8]  [ 800/1527]  eta: 1:06:21  lr: 0.000256  loss: 0.2124 (0.2181)  time: 5.6249  data: 0.0088  max mem: 22633
[20:30:24.279913] Epoch: [8]  [ 820/1527]  eta: 1:04:33  lr: 0.000256  loss: 0.2097 (0.2179)  time: 5.5613  data: 0.0292  max mem: 22633
[20:32:10.262626] Epoch: [8]  [ 840/1527]  eta: 1:02:41  lr: 0.000257  loss: 0.2104 (0.2178)  time: 5.2990  data: 0.0316  max mem: 22633
[20:34:06.298928] Epoch: [8]  [ 860/1527]  eta: 1:00:56  lr: 0.000257  loss: 0.2087 (0.2176)  time: 5.8017  data: 0.0215  max mem: 22633
[20:35:58.677657] Epoch: [8]  [ 880/1527]  eta: 0:59:08  lr: 0.000257  loss: 0.2121 (0.2175)  time: 5.6189  data: 0.0038  max mem: 22633
[20:37:46.632955] Epoch: [8]  [ 900/1527]  eta: 0:57:18  lr: 0.000258  loss: 0.2110 (0.2174)  time: 5.3977  data: 0.0083  max mem: 22633
[20:39:27.063942] Epoch: [8]  [ 920/1527]  eta: 0:55:22  lr: 0.000258  loss: 0.2095 (0.2172)  time: 5.0215  data: 0.0146  max mem: 22633
[20:41:14.543360] Epoch: [8]  [ 940/1527]  eta: 0:53:31  lr: 0.000258  loss: 0.2072 (0.2170)  time: 5.3739  data: 0.0375  max mem: 22633
[20:43:04.708307] Epoch: [8]  [ 960/1527]  eta: 0:51:42  lr: 0.000259  loss: 0.2097 (0.2169)  time: 5.5082  data: 0.0417  max mem: 22633
[20:44:59.374403] Epoch: [8]  [ 980/1527]  eta: 0:49:56  lr: 0.000259  loss: 0.2105 (0.2168)  time: 5.7332  data: 0.0346  max mem: 22633
[20:46:53.095763] Epoch: [8]  [1000/1527]  eta: 0:48:08  lr: 0.000260  loss: 0.2077 (0.2166)  time: 5.6860  data: 0.0063  max mem: 22633
[20:48:41.122425] Epoch: [8]  [1020/1527]  eta: 0:46:18  lr: 0.000260  loss: 0.2082 (0.2165)  time: 5.4013  data: 0.0037  max mem: 22633
[20:50:26.946141] Epoch: [8]  [1040/1527]  eta: 0:44:26  lr: 0.000260  loss: 0.2071 (0.2163)  time: 5.2911  data: 0.1162  max mem: 22633
[20:52:20.251583] Epoch: [8]  [1060/1527]  eta: 0:42:39  lr: 0.000261  loss: 0.2082 (0.2162)  time: 5.6652  data: 0.5863  max mem: 22633
[20:54:08.714557] Epoch: [8]  [1080/1527]  eta: 0:40:49  lr: 0.000261  loss: 0.2093 (0.2161)  time: 5.4231  data: 0.1217  max mem: 22633
[20:55:58.900618] Epoch: [8]  [1100/1527]  eta: 0:38:59  lr: 0.000262  loss: 0.2088 (0.2160)  time: 5.5092  data: 0.0101  max mem: 22633
[20:57:48.928268] Epoch: [8]  [1120/1527]  eta: 0:37:10  lr: 0.000262  loss: 0.2069 (0.2158)  time: 5.5013  data: 0.0117  max mem: 22633
[20:59:44.126503] Epoch: [8]  [1140/1527]  eta: 0:35:22  lr: 0.000262  loss: 0.2066 (0.2157)  time: 5.7598  data: 0.0004  max mem: 22633
[21:01:31.886688] Epoch: [8]  [1160/1527]  eta: 0:33:32  lr: 0.000263  loss: 0.2072 (0.2155)  time: 5.3877  data: 0.0393  max mem: 22633
[21:03:23.980921] Epoch: [8]  [1180/1527]  eta: 0:31:43  lr: 0.000263  loss: 0.2069 (0.2154)  time: 5.6046  data: 0.0463  max mem: 22633
[21:05:22.309096] Epoch: [8]  [1200/1527]  eta: 0:29:55  lr: 0.000264  loss: 0.2066 (0.2152)  time: 5.9163  data: 0.0169  max mem: 22633
[21:07:15.876347] Epoch: [8]  [1220/1527]  eta: 0:28:07  lr: 0.000264  loss: 0.2050 (0.2151)  time: 5.6783  data: 0.0064  max mem: 22633
[21:09:06.168898] Epoch: [8]  [1240/1527]  eta: 0:26:17  lr: 0.000264  loss: 0.2051 (0.2149)  time: 5.5146  data: 0.0081  max mem: 22633
[21:10:53.683598] Epoch: [8]  [1260/1527]  eta: 0:24:26  lr: 0.000265  loss: 0.2051 (0.2148)  time: 5.3757  data: 0.0004  max mem: 22633
[21:12:56.263647] Epoch: [8]  [1280/1527]  eta: 0:22:39  lr: 0.000265  loss: 0.2038 (0.2146)  time: 6.1289  data: 0.0047  max mem: 22633
[21:14:54.157180] Epoch: [8]  [1300/1527]  eta: 0:20:50  lr: 0.000266  loss: 0.2065 (0.2145)  time: 5.8942  data: 0.0041  max mem: 22633
[21:16:37.075658] Epoch: [8]  [1320/1527]  eta: 0:18:59  lr: 0.000266  loss: 0.2072 (0.2144)  time: 5.1458  data: 0.0003  max mem: 22633
[21:18:28.286302] Epoch: [8]  [1340/1527]  eta: 0:17:09  lr: 0.000266  loss: 0.2042 (0.2143)  time: 5.5605  data: 0.0004  max mem: 22633
[21:20:18.311271] Epoch: [8]  [1360/1527]  eta: 0:15:19  lr: 0.000267  loss: 0.2024 (0.2141)  time: 5.5012  data: 0.0003  max mem: 22633
[21:22:00.522866] Epoch: [8]  [1380/1527]  eta: 0:13:28  lr: 0.000267  loss: 0.2037 (0.2140)  time: 5.1105  data: 0.0003  max mem: 22633
[21:23:47.444623] Epoch: [8]  [1400/1527]  eta: 0:11:38  lr: 0.000268  loss: 0.2028 (0.2138)  time: 5.3460  data: 0.0089  max mem: 22633
[21:25:41.203944] Epoch: [8]  [1420/1527]  eta: 0:09:48  lr: 0.000268  loss: 0.2056 (0.2137)  time: 5.6879  data: 0.0129  max mem: 22633
[21:27:31.642037] Epoch: [8]  [1440/1527]  eta: 0:07:58  lr: 0.000268  loss: 0.2043 (0.2136)  time: 5.5218  data: 0.0215  max mem: 22633
[21:29:25.471428] Epoch: [8]  [1460/1527]  eta: 0:06:08  lr: 0.000269  loss: 0.2047 (0.2135)  time: 5.6914  data: 0.0220  max mem: 22633
[21:31:15.007797] Epoch: [8]  [1480/1527]  eta: 0:04:18  lr: 0.000269  loss: 0.2043 (0.2133)  time: 5.4768  data: 0.0004  max mem: 22633
[21:33:04.636252] Epoch: [8]  [1500/1527]  eta: 0:02:28  lr: 0.000269  loss: 0.2018 (0.2132)  time: 5.4813  data: 0.0543  max mem: 22633
[21:35:10.406485] Epoch: [8]  [1520/1527]  eta: 0:00:38  lr: 0.000270  loss: 0.2039 (0.2130)  time: 6.2883  data: 0.5223  max mem: 22633
[21:36:09.989933] Epoch: [8]  [1526/1527]  eta: 0:00:05  lr: 0.000270  loss: 0.2045 (0.2130)  time: 6.8678  data: 0.5222  max mem: 22633
[21:36:10.253593] Epoch: [8] Total time: 2:20:44 (5.5303 s / it)
[21:36:10.281229] Averaged stats: lr: 0.000270  loss: 0.2045 (0.2131)
[21:36:10.288559] log_dir: /proj/cloudrobotics-nest/users/Stacking/dataset/CloudGripper_push_1k/pre_trained_weights/vit_base_single_node_s_d
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[21:37:22.344298] torch.Size([256, 3, 224, 224])
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[21:38:40.716697] Epoch: [9]  [   0/1527]  eta: 1 day, 4:59:15  lr: 0.000270  loss: 0.2011 (0.2011)  time: 68.3400  data: 17.2460  max mem: 22633
[21:39:56.064789] Epoch: [9]  [  20/1527]  eta: 2:51:51  lr: 0.000270  loss: 0.2028 (0.2032)  time: 3.7673  data: 0.0004  max mem: 22633
[21:41:49.974155] Epoch: [9]  [  40/1527]  eta: 2:35:42  lr: 0.000271  loss: 0.2011 (0.2021)  time: 5.6954  data: 0.0161  max mem: 22633
[21:43:30.901862] Epoch: [9]  [  60/1527]  eta: 2:23:42  lr: 0.000271  loss: 0.2017 (0.2022)  time: 5.0463  data: 0.0007  max mem: 22633
[21:45:24.060855] Epoch: [9]  [  80/1527]  eta: 2:20:26  lr: 0.000272  loss: 0.2017 (0.2025)  time: 5.6576  data: 0.0005  max mem: 22633
[21:47:22.716138] Epoch: [9]  [ 100/1527]  eta: 2:18:57  lr: 0.000272  loss: 0.2007 (0.2022)  time: 5.9233  data: 0.0004  max mem: 22633
[21:49:07.293726] Epoch: [9]  [ 120/1527]  eta: 2:14:38  lr: 0.000272  loss: 0.2004 (0.2019)  time: 5.2288  data: 0.0004  max mem: 22633
[21:50:56.975934] Epoch: [9]  [ 140/1527]  eta: 2:11:52  lr: 0.000273  loss: 0.1991 (0.2017)  time: 5.4840  data: 0.0005  max mem: 22633
[21:52:54.942048] Epoch: [9]  [ 160/1527]  eta: 2:10:31  lr: 0.000273  loss: 0.1986 (0.2015)  time: 5.8982  data: 0.0004  max mem: 22633
[21:54:30.941915] Epoch: [9]  [ 180/1527]  eta: 2:06:18  lr: 0.000274  loss: 0.2010 (0.2017)  time: 4.7999  data: 0.0011  max mem: 22633
[21:56:22.927046] Epoch: [9]  [ 200/1527]  eta: 2:04:22  lr: 0.000274  loss: 0.1984 (0.2014)  time: 5.5992  data: 0.0004  max mem: 22633
[21:58:09.791092] Epoch: [9]  [ 220/1527]  eta: 2:01:56  lr: 0.000274  loss: 0.2007 (0.2015)  time: 5.3431  data: 0.0005  max mem: 22633
[21:59:51.342798] Epoch: [9]  [ 240/1527]  eta: 1:59:09  lr: 0.000275  loss: 0.1981 (0.2012)  time: 5.0775  data: 0.0003  max mem: 22633
[22:01:40.782535] Epoch: [9]  [ 260/1527]  eta: 1:57:10  lr: 0.000275  loss: 0.2003 (0.2011)  time: 5.4719  data: 0.0005  max mem: 22633
[22:03:28.653833] Epoch: [9]  [ 280/1527]  eta: 1:55:05  lr: 0.000276  loss: 0.1997 (0.2011)  time: 5.3935  data: 0.0004  max mem: 22633
[22:05:38.844879] Epoch: [9]  [ 300/1527]  eta: 1:54:33  lr: 0.000276  loss: 0.1979 (0.2009)  time: 6.5095  data: 0.0003  max mem: 22633
[22:07:25.261889] Epoch: [9]  [ 320/1527]  eta: 1:52:20  lr: 0.000276  loss: 0.1995 (0.2008)  time: 5.3208  data: 0.0004  max mem: 22633
[22:09:15.102818] Epoch: [9]  [ 340/1527]  eta: 1:50:22  lr: 0.000277  loss: 0.1960 (0.2006)  time: 5.4919  data: 0.0005  max mem: 22633
[22:11:02.411540] Epoch: [9]  [ 360/1527]  eta: 1:48:17  lr: 0.000277  loss: 0.1968 (0.2004)  time: 5.3653  data: 0.0004  max mem: 22633
[22:12:51.579297] Epoch: [9]  [ 380/1527]  eta: 1:46:19  lr: 0.000277  loss: 0.1979 (0.2003)  time: 5.4583  data: 0.0004  max mem: 22633
[22:14:40.459243] Epoch: [9]  [ 400/1527]  eta: 1:44:21  lr: 0.000278  loss: 0.1983 (0.2002)  time: 5.4439  data: 0.0004  max mem: 22633
[22:16:28.099074] Epoch: [9]  [ 420/1527]  eta: 1:42:21  lr: 0.000278  loss: 0.1968 (0.2001)  time: 5.3819  data: 0.0003  max mem: 22633
[22:18:29.633575] Epoch: [9]  [ 440/1527]  eta: 1:40:56  lr: 0.000279  loss: 0.1977 (0.2000)  time: 6.0767  data: 0.0005  max mem: 22633
[22:20:22.293227] Epoch: [9]  [ 460/1527]  eta: 1:39:07  lr: 0.000279  loss: 0.1974 (0.1999)  time: 5.6329  data: 0.0004  max mem: 22633
[22:22:11.893917] Epoch: [9]  [ 480/1527]  eta: 1:37:12  lr: 0.000279  loss: 0.1967 (0.1997)  time: 5.4800  data: 0.0005  max mem: 22633
[22:23:59.712898] Epoch: [9]  [ 500/1527]  eta: 1:35:13  lr: 0.000280  loss: 0.1971 (0.1996)  time: 5.3909  data: 0.0003  max mem: 22633

[22:25:49.530056] Epoch: [9]  [ 520/1527]  eta: 1:33:19  lr: 0.000280  loss: 0.1969 (0.1995)  time: 5.4908  data: 0.0005  max mem: 22633
[22:27:27.238701] Epoch: [9]  [ 540/1527]  eta: 1:31:03  lr: 0.000281  loss: 0.1941 (0.1994)  time: 4.8853  data: 0.0005  max mem: 22633
[22:29:22.411187] Epoch: [9]  [ 560/1527]  eta: 1:29:20  lr: 0.000281  loss: 0.1957 (0.1992)  time: 5.7585  data: 0.0005  max mem: 22633
[22:31:17.952546] Epoch: [9]  [ 580/1527]  eta: 1:27:37  lr: 0.000281  loss: 0.1940 (0.1991)  time: 5.7770  data: 0.0004  max mem: 22633
[22:33:08.659784] Epoch: [9]  [ 600/1527]  eta: 1:25:45  lr: 0.000282  loss: 0.1953 (0.1990)  time: 5.5353  data: 0.0003  max mem: 22633
[22:34:55.130101] Epoch: [9]  [ 620/1527]  eta: 1:23:47  lr: 0.000282  loss: 0.1933 (0.1989)  time: 5.3234  data: 0.0004  max mem: 22633
[22:36:42.577687] Epoch: [9]  [ 640/1527]  eta: 1:21:51  lr: 0.000283  loss: 0.1937 (0.1988)  time: 5.3589  data: 0.0003  max mem: 22633
[22:38:38.960719] Epoch: [9]  [ 660/1527]  eta: 1:20:08  lr: 0.000283  loss: 0.1939 (0.1986)  time: 5.8191  data: 0.0003  max mem: 22633
[22:40:20.568406] Epoch: [9]  [ 680/1527]  eta: 1:18:06  lr: 0.000283  loss: 0.1925 (0.1985)  time: 5.0803  data: 0.0045  max mem: 22633
[22:42:10.181878] Epoch: [9]  [ 700/1527]  eta: 1:16:14  lr: 0.000284  loss: 0.1938 (0.1984)  time: 5.4805  data: 0.0085  max mem: 22633
[22:43:53.250368] Epoch: [9]  [ 720/1527]  eta: 1:14:15  lr: 0.000284  loss: 0.1926 (0.1982)  time: 5.1533  data: 0.0004  max mem: 22633
[22:45:49.400329] Epoch: [9]  [ 740/1527]  eta: 1:12:30  lr: 0.000285  loss: 0.1930 (0.1981)  time: 5.8074  data: 0.0081  max mem: 22633
[22:47:48.430679] Epoch: [9]  [ 760/1527]  eta: 1:10:48  lr: 0.000285  loss: 0.1932 (0.1980)  time: 5.9514  data: 0.0004  max mem: 22633
[22:49:35.059044] Epoch: [9]  [ 780/1527]  eta: 1:08:53  lr: 0.000285  loss: 0.1922 (0.1978)  time: 5.3313  data: 0.0004  max mem: 22633
[22:51:30.381911] Epoch: [9]  [ 800/1527]  eta: 1:07:07  lr: 0.000286  loss: 0.1917 (0.1977)  time: 5.7661  data: 0.0003  max mem: 22633
[22:53:33.946659] Epoch: [9]  [ 820/1527]  eta: 1:05:27  lr: 0.000286  loss: 0.1925 (0.1976)  time: 6.1782  data: 0.0004  max mem: 22633
[22:55:19.786162] Epoch: [9]  [ 840/1527]  eta: 1:03:32  lr: 0.000287  loss: 0.1922 (0.1975)  time: 5.2919  data: 0.0003  max mem: 22633
[22:57:24.625177] Epoch: [9]  [ 860/1527]  eta: 1:01:52  lr: 0.000287  loss: 0.1908 (0.1973)  time: 6.2419  data: 0.0004  max mem: 22633
[22:59:13.869250] Epoch: [9]  [ 880/1527]  eta: 0:59:59  lr: 0.000287  loss: 0.1916 (0.1972)  time: 5.4621  data: 0.0004  max mem: 22633
[23:01:01.643189] Epoch: [9]  [ 900/1527]  eta: 0:58:05  lr: 0.000288  loss: 0.1919 (0.1971)  time: 5.3886  data: 0.0003  max mem: 22633
[23:02:47.173666] Epoch: [9]  [ 920/1527]  eta: 0:56:10  lr: 0.000288  loss: 0.1928 (0.1970)  time: 5.2764  data: 0.0003  max mem: 22633
[23:04:39.997758] Epoch: [9]  [ 940/1527]  eta: 0:54:20  lr: 0.000288  loss: 0.1911 (0.1968)  time: 5.6411  data: 0.0118  max mem: 22633
[23:06:24.282139] Epoch: [9]  [ 960/1527]  eta: 0:52:25  lr: 0.000289  loss: 0.1900 (0.1967)  time: 5.2139  data: 0.0175  max mem: 22633
[23:08:23.989453] Epoch: [9]  [ 980/1527]  eta: 0:50:39  lr: 0.000289  loss: 0.1913 (0.1966)  time: 5.9853  data: 0.0177  max mem: 22633
[23:10:14.536865] Epoch: [9]  [1000/1527]  eta: 0:48:48  lr: 0.000290  loss: 0.1911 (0.1965)  time: 5.5273  data: 0.0004  max mem: 22633
[23:11:59.289152] Epoch: [9]  [1020/1527]  eta: 0:46:53  lr: 0.000290  loss: 0.1895 (0.1964)  time: 5.2376  data: 0.0003  max mem: 22633
[23:13:51.476908] Epoch: [9]  [1040/1527]  eta: 0:45:03  lr: 0.000290  loss: 0.1884 (0.1963)  time: 5.6093  data: 0.0004  max mem: 22633
[23:15:56.672106] Epoch: [9]  [1060/1527]  eta: 0:43:18  lr: 0.000291  loss: 0.1888 (0.1961)  time: 6.2594  data: 0.0003  max mem: 22633
[23:17:42.478865] Epoch: [9]  [1080/1527]  eta: 0:41:24  lr: 0.000291  loss: 0.1907 (0.1960)  time: 5.2902  data: 0.0003  max mem: 22633
[23:19:20.006166] Epoch: [9]  [1100/1527]  eta: 0:39:28  lr: 0.000292  loss: 0.1894 (0.1959)  time: 4.8763  data: 0.0114  max mem: 22633
[23:21:23.029514] Epoch: [9]  [1120/1527]  eta: 0:37:41  lr: 0.000292  loss: 0.1893 (0.1958)  time: 6.1511  data: 0.0128  max mem: 22633
[23:23:17.052290] Epoch: [9]  [1140/1527]  eta: 0:35:51  lr: 0.000292  loss: 0.1893 (0.1957)  time: 5.7011  data: 0.0042  max mem: 22633
[23:25:05.529009] Epoch: [9]  [1160/1527]  eta: 0:33:59  lr: 0.000293  loss: 0.1887 (0.1956)  time: 5.4238  data: 0.0041  max mem: 22633
[23:26:46.920126] Epoch: [9]  [1180/1527]  eta: 0:32:05  lr: 0.000293  loss: 0.1889 (0.1955)  time: 5.0695  data: 0.0057  max mem: 22633
[23:28:30.114038] Epoch: [9]  [1200/1527]  eta: 0:30:12  lr: 0.000294  loss: 0.1865 (0.1954)  time: 5.1596  data: 0.0004  max mem: 22633
[23:30:27.420312] Epoch: [9]  [1220/1527]  eta: 0:28:23  lr: 0.000294  loss: 0.1867 (0.1952)  time: 5.8653  data: 0.1096  max mem: 22633
[23:32:10.695309] Epoch: [9]  [1240/1527]  eta: 0:26:30  lr: 0.000294  loss: 0.1897 (0.1951)  time: 5.1637  data: 0.0163  max mem: 22633
[23:33:57.066747] Epoch: [9]  [1260/1527]  eta: 0:24:38  lr: 0.000295  loss: 0.1843 (0.1950)  time: 5.3185  data: 0.2124  max mem: 22633
[23:35:52.557578] Epoch: [9]  [1280/1527]  eta: 0:22:48  lr: 0.000295  loss: 0.1877 (0.1949)  time: 5.7745  data: 0.0128  max mem: 22633
[23:37:45.268633] Epoch: [9]  [1300/1527]  eta: 0:20:58  lr: 0.000296  loss: 0.1874 (0.1948)  time: 5.6355  data: 0.0025  max mem: 22633
[23:39:37.498676] Epoch: [9]  [1320/1527]  eta: 0:19:07  lr: 0.000296  loss: 0.1856 (0.1947)  time: 5.6114  data: 0.0004  max mem: 22633
[23:41:23.197097] Epoch: [9]  [1340/1527]  eta: 0:17:16  lr: 0.000296  loss: 0.1889 (0.1946)  time: 5.2848  data: 0.0753  max mem: 22633
[23:43:21.074666] Epoch: [9]  [1360/1527]  eta: 0:15:26  lr: 0.000297  loss: 0.1843 (0.1944)  time: 5.8935  data: 0.0123  max mem: 22633
[23:45:13.076923] Epoch: [9]  [1380/1527]  eta: 0:13:35  lr: 0.000297  loss: 0.1866 (0.1943)  time: 5.6000  data: 0.0004  max mem: 22633
[23:47:02.588021] Epoch: [9]  [1400/1527]  eta: 0:11:44  lr: 0.000298  loss: 0.1867 (0.1942)  time: 5.4755  data: 0.0004  max mem: 22633
[23:48:58.372883] Epoch: [9]  [1420/1527]  eta: 0:09:53  lr: 0.000298  loss: 0.1850 (0.1941)  time: 5.7892  data: 0.0005  max mem: 22633
[23:50:45.032973] Epoch: [9]  [1440/1527]  eta: 0:08:02  lr: 0.000298  loss: 0.1852 (0.1940)  time: 5.3329  data: 0.0004  max mem: 22633
[23:52:49.913163] Epoch: [9]  [1460/1527]  eta: 0:06:12  lr: 0.000299  loss: 0.1885 (0.1939)  time: 6.2435  data: 0.0003  max mem: 22633
[23:54:40.091232] Epoch: [9]  [1480/1527]  eta: 0:04:21  lr: 0.000299  loss: 0.1860 (0.1938)  time: 5.5088  data: 0.0003  max mem: 22633
[23:56:23.524805] Epoch: [9]  [1500/1527]  eta: 0:02:29  lr: 0.000299  loss: 0.1827 (0.1937)  time: 5.1713  data: 0.0183  max mem: 22633
[23:58:18.323098] Epoch: [9]  [1520/1527]  eta: 0:00:38  lr: 0.000300  loss: 0.1855 (0.1936)  time: 5.7399  data: 0.0024  max mem: 22633
[23:58:41.380819] Epoch: [9]  [1526/1527]  eta: 0:00:05  lr: 0.000300  loss: 0.1838 (0.1935)  time: 5.9617  data: 0.0023  max mem: 22633
[23:58:41.642389] Epoch: [9] Total time: 2:21:09 (5.5463 s / it)
[23:58:41.644682] Averaged stats: lr: 0.000300  loss: 0.1838 (0.1935)
[23:58:41.649562] log_dir: /proj/cloudrobotics-nest/users/Stacking/dataset/CloudGripper_push_1k/pre_trained_weights/vit_base_single_node_s_d
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[23:59:46.833835] torch.Size([256, 3, 224, 224])
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[00:01:03.156054] Epoch: [10]  [   0/1527]  eta: 17:29:57  lr: 0.000300  loss: 0.1941 (0.1941)  time: 41.2558  data: 32.8981  max mem: 22633
[00:02:27.244290] Epoch: [10]  [  20/1527]  eta: 2:29:54  lr: 0.000300  loss: 0.1840 (0.1845)  time: 4.2043  data: 2.3558  max mem: 22633
[00:04:21.211190] Epoch: [10]  [  40/1527]  eta: 2:24:39  lr: 0.000301  loss: 0.1840 (0.1846)  time: 5.6983  data: 2.2404  max mem: 22633
[00:06:10.199195] Epoch: [10]  [  60/1527]  eta: 2:19:23  lr: 0.000301  loss: 0.1853 (0.1848)  time: 5.4238  data: 2.0436  max mem: 22633
[00:08:08.150883] Epoch: [10]  [  80/1527]  eta: 2:18:39  lr: 0.000302  loss: 0.1841 (0.1846)  time: 5.8975  data: 1.6430  max mem: 22633
[00:09:53.563211] Epoch: [10]  [ 100/1527]  eta: 2:14:29  lr: 0.000302  loss: 0.1829 (0.1843)  time: 5.2705  data: 0.7701  max mem: 22633
[00:11:40.540304] Epoch: [10]  [ 120/1527]  eta: 2:11:25  lr: 0.000302  loss: 0.1846 (0.1846)  time: 5.3488  data: 0.8885  max mem: 22633
[00:13:49.736056] Epoch: [10]  [ 140/1527]  eta: 2:12:21  lr: 0.000303  loss: 0.1811 (0.1843)  time: 6.4594  data: 1.4773  max mem: 22633
[00:15:42.870113] Epoch: [10]  [ 160/1527]  eta: 2:10:15  lr: 0.000303  loss: 0.1824 (0.1841)  time: 5.6566  data: 0.0872  max mem: 22633
[00:17:31.274038] Epoch: [10]  [ 180/1527]  eta: 2:07:36  lr: 0.000304  loss: 0.1824 (0.1839)  time: 5.4201  data: 0.0655  max mem: 22633
[00:19:22.870776] Epoch: [10]  [ 200/1527]  eta: 2:05:29  lr: 0.000304  loss: 0.1825 (0.1838)  time: 5.5797  data: 0.0647  max mem: 22633
[00:21:08.699036] Epoch: [10]  [ 220/1527]  eta: 2:02:50  lr: 0.000304  loss: 0.1824 (0.1838)  time: 5.2911  data: 0.0285  max mem: 22633
[00:22:59.441014] Epoch: [10]  [ 240/1527]  eta: 2:00:46  lr: 0.000305  loss: 0.1832 (0.1838)  time: 5.5370  data: 0.0292  max mem: 22633
[00:24:39.918225] Epoch: [10]  [ 260/1527]  eta: 1:57:55  lr: 0.000305  loss: 0.1810 (0.1837)  time: 5.0238  data: 0.0247  max mem: 22633
[00:26:30.234897] Epoch: [10]  [ 280/1527]  eta: 1:55:57  lr: 0.000306  loss: 0.1812 (0.1835)  time: 5.5157  data: 0.3148  max mem: 22633
[00:28:23.713818] Epoch: [10]  [ 300/1527]  eta: 1:54:13  lr: 0.000306  loss: 0.1829 (0.1835)  time: 5.6739  data: 0.1286  max mem: 22633
[00:30:19.544523] Epoch: [10]  [ 320/1527]  eta: 1:52:37  lr: 0.000306  loss: 0.1814 (0.1834)  time: 5.7914  data: 0.0161  max mem: 22633
[00:32:01.886212] Epoch: [10]  [ 340/1527]  eta: 1:50:11  lr: 0.000307  loss: 0.1814 (0.1833)  time: 5.1170  data: 0.0149  max mem: 22633
[00:33:44.153958] Epoch: [10]  [ 360/1527]  eta: 1:47:50  lr: 0.000307  loss: 0.1831 (0.1833)  time: 5.1133  data: 0.0862  max mem: 22633
[00:35:33.339559] Epoch: [10]  [ 380/1527]  eta: 1:45:54  lr: 0.000307  loss: 0.1825 (0.1832)  time: 5.4592  data: 0.1004  max mem: 22633
[00:37:18.062485] Epoch: [10]  [ 400/1527]  eta: 1:43:46  lr: 0.000308  loss: 0.1805 (0.1831)  time: 5.2361  data: 0.0122  max mem: 22633
[00:39:04.381380] Epoch: [10]  [ 420/1527]  eta: 1:41:45  lr: 0.000308  loss: 0.1813 (0.1830)  time: 5.3158  data: 0.4406  max mem: 22633
[00:40:52.818276] Epoch: [10]  [ 440/1527]  eta: 1:39:50  lr: 0.000309  loss: 0.1787 (0.1829)  time: 5.4218  data: 0.0270  max mem: 22633
[00:42:43.323064] Epoch: [10]  [ 460/1527]  eta: 1:38:00  lr: 0.000309  loss: 0.1783 (0.1827)  time: 5.5252  data: 0.0666  max mem: 22633
[00:44:33.703734] Epoch: [10]  [ 480/1527]  eta: 1:36:11  lr: 0.000309  loss: 0.1804 (0.1826)  time: 5.5190  data: 0.1533  max mem: 22633
[00:46:18.059323] Epoch: [10]  [ 500/1527]  eta: 1:34:08  lr: 0.000310  loss: 0.1803 (0.1825)  time: 5.2175  data: 0.0347  max mem: 22633
[00:48:09.937887] Epoch: [10]  [ 520/1527]  eta: 1:32:22  lr: 0.000310  loss: 0.1792 (0.1824)  time: 5.5938  data: 0.0124  max mem: 22633
[00:50:02.327159] Epoch: [10]  [ 540/1527]  eta: 1:30:36  lr: 0.000311  loss: 0.1789 (0.1823)  time: 5.6194  data: 0.0256  max mem: 22633
[00:51:56.599116] Epoch: [10]  [ 560/1527]  eta: 1:28:53  lr: 0.000311  loss: 0.1773 (0.1822)  time: 5.7135  data: 0.0316  max mem: 22633
[00:53:40.297545] Epoch: [10]  [ 580/1527]  eta: 1:26:52  lr: 0.000311  loss: 0.1788 (0.1821)  time: 5.1849  data: 0.0306  max mem: 22633
[00:55:27.956672] Epoch: [10]  [ 600/1527]  eta: 1:24:58  lr: 0.000312  loss: 0.1777 (0.1820)  time: 5.3776  data: 0.0309  max mem: 22633
[00:57:28.985986] Epoch: [10]  [ 620/1527]  eta: 1:23:24  lr: 0.000312  loss: 0.1779 (0.1819)  time: 6.0514  data: 0.0315  max mem: 22633
[00:59:21.534586] Epoch: [10]  [ 640/1527]  eta: 1:21:37  lr: 0.000313  loss: 0.1786 (0.1818)  time: 5.6273  data: 0.0502  max mem: 22633
[01:01:11.950427] Epoch: [10]  [ 660/1527]  eta: 1:19:46  lr: 0.000313  loss: 0.1765 (0.1817)  time: 5.5207  data: 0.2933  max mem: 22633
[01:03:08.792272] Epoch: [10]  [ 680/1527]  eta: 1:18:04  lr: 0.000313  loss: 0.1782 (0.1816)  time: 5.8420  data: 0.3431  max mem: 22633
[01:05:00.044105] Epoch: [10]  [ 700/1527]  eta: 1:16:14  lr: 0.000314  loss: 0.1781 (0.1816)  time: 5.5621  data: 0.0440  max mem: 22633
[01:06:45.126262] Epoch: [10]  [ 720/1527]  eta: 1:14:17  lr: 0.000314  loss: 0.1770 (0.1814)  time: 5.2540  data: 0.4346  max mem: 22633
[01:08:41.144339] Epoch: [10]  [ 740/1527]  eta: 1:12:32  lr: 0.000315  loss: 0.1766 (0.1813)  time: 5.8008  data: 1.2022  max mem: 22633
[01:10:34.738538] Epoch: [10]  [ 760/1527]  eta: 1:10:45  lr: 0.000315  loss: 0.1791 (0.1813)  time: 5.6796  data: 2.3056  max mem: 22633
[01:12:19.902777] Epoch: [10]  [ 780/1527]  eta: 1:08:49  lr: 0.000315  loss: 0.1770 (0.1812)  time: 5.2581  data: 1.0761  max mem: 22633
[01:14:09.421023] Epoch: [10]  [ 800/1527]  eta: 1:06:57  lr: 0.000316  loss: 0.1788 (0.1811)  time: 5.4758  data: 1.8262  max mem: 22633
[01:15:58.995015] Epoch: [10]  [ 820/1527]  eta: 1:05:06  lr: 0.000316  loss: 0.1787 (0.1811)  time: 5.4786  data: 2.6792  max mem: 22633
[01:17:54.685816] Epoch: [10]  [ 840/1527]  eta: 1:03:20  lr: 0.000317  loss: 0.1747 (0.1810)  time: 5.7845  data: 2.5156  max mem: 22633
[01:19:48.372360] Epoch: [10]  [ 860/1527]  eta: 1:01:31  lr: 0.000317  loss: 0.1769 (0.1809)  time: 5.6843  data: 2.9964  max mem: 22633
[01:21:42.543222] Epoch: [10]  [ 880/1527]  eta: 0:59:43  lr: 0.000317  loss: 0.1763 (0.1808)  time: 5.7085  data: 2.3773  max mem: 22633
[01:23:43.132149] Epoch: [10]  [ 900/1527]  eta: 0:57:59  lr: 0.000318  loss: 0.1756 (0.1807)  time: 6.0294  data: 2.1738  max mem: 22633
[01:25:24.610793] Epoch: [10]  [ 920/1527]  eta: 0:56:02  lr: 0.000318  loss: 0.1745 (0.1805)  time: 5.0739  data: 1.0300  max mem: 22633
[01:27:14.125419] Epoch: [10]  [ 940/1527]  eta: 0:54:10  lr: 0.000318  loss: 0.1760 (0.1805)  time: 5.4757  data: 1.3493  max mem: 22633
[01:29:08.917887] Epoch: [10]  [ 960/1527]  eta: 0:52:22  lr: 0.000319  loss: 0.1769 (0.1804)  time: 5.7392  data: 1.5614  max mem: 22633
[01:30:53.423405] Epoch: [10]  [ 980/1527]  eta: 0:50:28  lr: 0.000319  loss: 0.1739 (0.1803)  time: 5.2252  data: 0.9713  max mem: 22633
[01:32:42.682974] Epoch: [10]  [1000/1527]  eta: 0:48:36  lr: 0.000320  loss: 0.1773 (0.1803)  time: 5.4629  data: 0.5096  max mem: 22633
[01:34:38.721055] Epoch: [10]  [1020/1527]  eta: 0:46:48  lr: 0.000320  loss: 0.1751 (0.1802)  time: 5.8016  data: 0.5010  max mem: 22633
[01:36:33.977306] Epoch: [10]  [1040/1527]  eta: 0:44:59  lr: 0.000320  loss: 0.1761 (0.1801)  time: 5.7627  data: 0.6646  max mem: 22633
[01:38:28.247523] Epoch: [10]  [1060/1527]  eta: 0:43:10  lr: 0.000321  loss: 0.1737 (0.1800)  time: 5.7134  data: 0.0307  max mem: 22633
[01:40:26.882584] Epoch: [10]  [1080/1527]  eta: 0:41:22  lr: 0.000321  loss: 0.1741 (0.1799)  time: 5.9317  data: 0.0003  max mem: 22633
[01:42:20.539338] Epoch: [10]  [1100/1527]  eta: 0:39:32  lr: 0.000322  loss: 0.1742 (0.1798)  time: 5.6828  data: 0.0008  max mem: 22633
[01:44:25.872797] Epoch: [10]  [1120/1527]  eta: 0:37:46  lr: 0.000322  loss: 0.1725 (0.1797)  time: 6.2666  data: 0.0004  max mem: 22633
[01:46:19.251870] Epoch: [10]  [1140/1527]  eta: 0:35:56  lr: 0.000322  loss: 0.1730 (0.1796)  time: 5.6689  data: 0.0004  max mem: 22633
[01:47:57.297987] Epoch: [10]  [1160/1527]  eta: 0:34:00  lr: 0.000323  loss: 0.1746 (0.1795)  time: 4.9022  data: 0.0127  max mem: 22633
[01:49:38.361206] Epoch: [10]  [1180/1527]  eta: 0:32:06  lr: 0.000323  loss: 0.1743 (0.1794)  time: 5.0528  data: 0.0136  max mem: 22633
[01:51:24.814348] Epoch: [10]  [1200/1527]  eta: 0:30:13  lr: 0.000324  loss: 0.1768 (0.1794)  time: 5.3226  data: 0.0425  max mem: 22633
[01:52:59.884404] Epoch: [10]  [1220/1527]  eta: 0:28:18  lr: 0.000324  loss: 0.1735 (0.1793)  time: 4.7534  data: 0.0405  max mem: 22633
[01:55:03.173669] Epoch: [10]  [1240/1527]  eta: 0:26:31  lr: 0.000324  loss: 0.1717 (0.1792)  time: 6.1644  data: 0.0384  max mem: 22633
[01:57:06.678704] Epoch: [10]  [1260/1527]  eta: 0:24:43  lr: 0.000325  loss: 0.1721 (0.1791)  time: 6.1752  data: 0.0334  max mem: 22633
[01:59:02.763719] Epoch: [10]  [1280/1527]  eta: 0:22:52  lr: 0.000325  loss: 0.1713 (0.1790)  time: 5.8042  data: 0.0255  max mem: 22633
[02:00:53.008287] Epoch: [10]  [1300/1527]  eta: 0:21:01  lr: 0.000326  loss: 0.1731 (0.1789)  time: 5.5122  data: 0.0003  max mem: 22633
[02:02:35.751258] Epoch: [10]  [1320/1527]  eta: 0:19:09  lr: 0.000326  loss: 0.1725 (0.1788)  time: 5.1371  data: 0.0219  max mem: 22633
[02:04:32.110211] Epoch: [10]  [1340/1527]  eta: 0:17:18  lr: 0.000326  loss: 0.1709 (0.1787)  time: 5.8179  data: 0.1276  max mem: 22633
[02:06:23.406904] Epoch: [10]  [1360/1527]  eta: 0:15:27  lr: 0.000327  loss: 0.1707 (0.1786)  time: 5.5648  data: 1.0074  max mem: 22633
[02:08:14.633857] Epoch: [10]  [1380/1527]  eta: 0:13:36  lr: 0.000327  loss: 0.1711 (0.1785)  time: 5.5613  data: 0.7763  max mem: 22633
[02:09:57.356796] Epoch: [10]  [1400/1527]  eta: 0:11:44  lr: 0.000328  loss: 0.1720 (0.1784)  time: 5.1361  data: 1.0408  max mem: 22633
[02:11:51.665970] Epoch: [10]  [1420/1527]  eta: 0:09:54  lr: 0.000328  loss: 0.1682 (0.1783)  time: 5.7154  data: 0.7713  max mem: 22633
[02:13:43.352837] Epoch: [10]  [1440/1527]  eta: 0:08:03  lr: 0.000328  loss: 0.1718 (0.1782)  time: 5.5843  data: 1.2443  max mem: 22633
[02:15:42.190855] Epoch: [10]  [1460/1527]  eta: 0:06:12  lr: 0.000329  loss: 0.1693 (0.1781)  time: 5.9418  data: 0.6421  max mem: 22633
[02:17:28.050553] Epoch: [10]  [1480/1527]  eta: 0:04:21  lr: 0.000329  loss: 0.1697 (0.1780)  time: 5.2929  data: 0.1944  max mem: 22633
[02:19:10.222606] Epoch: [10]  [1500/1527]  eta: 0:02:29  lr: 0.000329  loss: 0.1716 (0.1779)  time: 5.1085  data: 0.0210  max mem: 22633
[02:21:21.852765] Epoch: [10]  [1520/1527]  eta: 0:00:38  lr: 0.000330  loss: 0.1700 (0.1778)  time: 6.5814  data: 0.0108  max mem: 22633
[02:22:46.080566] Epoch: [10]  [1526/1527]  eta: 0:00:05  lr: 0.000330  loss: 0.1700 (0.1778)  time: 8.8361  data: 0.0103  max mem: 22633
[02:22:46.335034] Epoch: [10] Total time: 2:22:24 (5.5956 s / it)
[02:22:46.336282] Averaged stats: lr: 0.000330  loss: 0.1700 (0.1778)
[02:22:48.403653] log_dir: /proj/cloudrobotics-nest/users/Stacking/dataset/CloudGripper_push_1k/pre_trained_weights/vit_base_single_node_s_d
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[02:23:49.206651] torch.Size([256, 3, 224, 224])
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/x_shuji/.conda/envs/data4robotics/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[02:25:15.400013] Epoch: [11]  [   0/1527]  eta: 1 day, 7:54:12  lr: 0.000330  loss: 0.1706 (0.1706)  time: 75.2144  data: 23.1969  max mem: 22633
submitit WARNING (2024-08-16 09:57:45,534) - Bypassing signal SIGCONT
submitit WARNING (2024-08-16 09:57:45,539) - Bypassing signal SIGTERM
submitit WARNING (2024-08-16 09:57:45,534) - Bypassing signal SIGCONT
